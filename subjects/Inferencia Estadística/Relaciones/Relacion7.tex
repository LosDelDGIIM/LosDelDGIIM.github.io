\newpage
\section{Contraste de hipótesis}

% Están hechos: 1, 2, 3, 9, 10, 13, 14

\begin{ejercicio}
    Se toma una observación de una variable con distribución de Poisson para contrastar que la media vale 1 frente a que vale 2.
    \begin{enumerate}[label=\alph*)]
        \item Construir un test no aleatorizado con nivel de significación $0.05$ para el contraste planteado. Calcular las probabilidades de cometer error de tipo 1 y de tipo 2, el tamaño y la potencia del test frente a la hipótesis alternativa.
        \item ¿Cómo debe aleatorizarse el test para alcanzar el tamaño $0.05$? ¿Cuál es la potencia de este test?
    \end{enumerate}
    
    \textbf{Solución}
    \begin{enumerate}[label=\alph*)]
        \item Sea $X\rightsquigarrow \cc{P}(\lm)$, queremos resolver el contraste:
            \begin{equation*}
                \left\{\begin{array}{l}
                    H_0 : \lm = 1 \\
                    H_1 : \lm = 2
                \end{array}\right.
            \end{equation*}
            Trabajaremos por tanto con:
            \begin{equation*}
                \Theta_0 = \{1\}, \qquad \Theta_1 = \{2\}, \qquad \Theta = \{1,2\}
            \end{equation*}
            y escribiremos $\lm_0 = 1$, $\lm_1 = 2$. Pensamos la forma que ha de tener el test: el espacio muestral de $X$ es $\mathbb{R}^+_0$:
            \begin{figure}[H]
                \centering
                \begin{tikzpicture}
                % Dibuja la recta real
                \draw[-Stealth] (-1,0) -- (3,0) node[right] {};

                % Marca los puntos 1 y 2
                \foreach \x in {0,1,2} {
                    \draw (\x,0.1) -- (\x,-0.1) node[below] {$\x$};
                }
                \end{tikzpicture}
            \end{figure}
            Es claro que cuanto más a la izquierda nos encontremos con dicha observación $X$, no rechazaremos la hipótesis nula, así como que cuanto más a la derecha estemos la rechazaremos. Por tanto, establecemos un cierto punto $c\in \mathbb{R}^+_0$ que delimite la región crítica del test (que será la región $\left]c,+\infty\right[$). Para determinar dicho punto $c$ imponemos un nivel de significación $\alpha = 0.05$. Por tanto, el test será de la forma:
            \begin{equation*}
                \varphi(X) = \left\{\begin{array}{ll}
                    1 & \text{si\ } X> c \\
                    0 & \text{si\ } X \leq c
                \end{array}\right. 
            \end{equation*}
            Imponemos nivel de significancia $\alpha$:
            \begin{equation*}
                \alpha \geq \sup_{\lm \in \Theta_0}\beta_\varphi(\lm) = \sup_{\lm\in \{\lm_0\}} \beta_\varphi(\lm) = \beta_\varphi(\lm_0) = E_{\lm_0}[\varphi]  = P_{\lm_0}[X>c]  = 1-P_{\lm_0}[X\leq c]
            \end{equation*}
            Y lo que hacemos ahora es ir probando con distintos valores de $c$ hasta acercarnos lo máximo posible a $\alpha = 0.05$ pero sin pasarnos:
            \begin{itemize}
                \item Para $c=0$:
                    \begin{equation*}
                        P_1[X\leq 0] = P_1[X = 0] = 0.3679 \quad\Longrightarrow\quad 1-P_1[X\leq 0] = 0.6321 > \alpha
                    \end{equation*}
                \item Para $c=1$:
                    \begin{align*}
                        P_1[X\leq 1] &= P_1[X=0] + P_1[X=1] = 0.3679 + 0.3679 = 0.7358  \\
                                     &\Longrightarrow 1-P_1[X\leq 1] = 0.2642 > \alpha
                    \end{align*}
                \item Para $c=2$:
                    \begin{align*}
                        P_1[X\leq 2] &= P_1[X\leq 1] + P_1[X=2] = 0.7358 + 0.1839 = 0.9197 \\
                                     &\Longrightarrow 1-P_1[X\leq 2] = 0.0803 > \alpha
                    \end{align*}
                \item Para $c=3$:
                    \begin{align*}
                        P_1[X\leq 3] &= P_1[X\leq 2] + P_1[X=3] = 0.9197 + 0.0613 = 0.981 \\
                                     &\Longrightarrow 1-P_1[X\leq 3] = 0.019 \leq \alpha
                    \end{align*}
            \end{itemize}
            Por tanto, el valor a tomar es $c=3$, de donde el test sería:
            \begin{equation*}
                \varphi(X) = \left\{\begin{array}{ll}
                    1 & \text{si\ } X> 3 \\
                    0 & \text{si\ } X \leq 3
                \end{array}\right. 
            \end{equation*}
            Calculamos ahora:
            \begin{description}
                \item [Probabilidad de cometer error tipo 1.] 
                    \begin{equation*}
                        P_{\lm\in \Theta_0}[X\in C] = P_{\lm_0}[X>3] = P_1[X>3] = 0.019
                    \end{equation*}
                \item [Probabilidad de cometer error tipo 2.]
                    \begin{align*}
                        P_{\lm \in \Theta_1}\left[X\in \overline{C}\right] &= P_{\lm_1}[X\leq 3] = P_2[X\leq 3] = \sum_{k=0}^{3} P_2[X=k] \\
                                                                           &= (0.1353 + 0.2707 + 0.2707 + 0.1804) = 0.8571
                    \end{align*}
                \item [Tamaño del test.] El tamaño resulta ser igual a la probabilidad encontrada cuando buscábamos el valor de $c$:
                    \begin{equation*}
                        \sup_{\lm \in \Theta_0}\beta_\varphi(\lm) = \beta_\varphi(\lm_0) = E_{\lm_0}[\varphi] = P_{\lm_0}[X>3] = 0.019
                    \end{equation*}
                \item [Potencia frente a hipótesis alternativa.] La potencia del test es:
                    \begin{align*}
                        \sup_{\lm \in \Theta_1} \beta_\varphi(\lm) &= \beta_\varphi(\lm_1) = E_{\lm_1}[\varphi] = P_{\lm_1}[X>3] = P_2[X>3] = 1-P_2[X\leq 3] \\
                                                                   &= 1- 0.8571 = 0.1429
                    \end{align*}
            \end{description}
        \item Para alcanzar un tamaño de $0.05$ mediante un test aleatoriezado, lo que hacemos ahora es considerar un test del tipo:
            \begin{equation*}
                \varphi(X) = \left\{\begin{array}{ll}
                    1 & \text{si\ } X>3 \\
                    \gamma & \text{si\ } X=3 \\
                    0 & \text{si\ } X<3 
                \end{array}\right. 
            \end{equation*}
            Para cierto $\gamma\in [0,1]$, de forma que a la hora de imponer un tamaño menor o igual que $\alpha=0.05$ calculemos $\gamma$ para obtener la igualdad. De esta forma, el tamaño del test es:
            \begin{equation*}
                \sup_{\lm \in \Theta_0}\beta_\varphi(\lm) = \beta_\varphi(\lm_0) = E_{\lm_0}[\varphi] = P_{\lm_0}[X>3] + \gamma P_{\lm_0}[X=3] = 0.019 + \gamma 0.0613
            \end{equation*}
            Si imponemos que sea igual a $\alpha$:
            \begin{equation*}
                0.05 = \alpha = 0.019 + \gamma \cdot 0.0613 \quad\Longrightarrow\quad \gamma = \frac{0.05 - 0.019}{0.0613} \approx 0.5057096
            \end{equation*}
            Calculamos la potencia del test:
            \begin{equation*}
                \sup_{\lm \in \Theta_1}\beta_\varphi(\lm) = E_{\lm_1}[\varphi] = P_{\lm_1}[X>3] + \gamma P_{\lm_1}[X=3] = 0.1429 + \gamma 0.1804 \approx 0.23413
            \end{equation*}
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Una urna contiene 10 bolas, blancas y negras. Para contrastar que el número de bolas blancas es 5 frente a que dicho número es 6 o 7, se extraen tres bolas con reemplazamiento y se rechaza $H_0$ sólo si se obtienen 2 o 3 bolas blancas. Calcular el tamaño de este test y la potencia frente a las alternativas.\\

    \noindent 
    Sea:
    \begin{equation*}
        X\equiv \text{``Número de bolas blancas en una extracción''} \rightsquigarrow B(1,p)
    \end{equation*}
    Se quiere resolver el contraste de hipótesis:
    \begin{equation*}
        \left\{\begin{array}{l}
            H_0 : p = p_0 =  \nicefrac{5}{10} \\
            H_1 : p \in \{\nicefrac{6}{10}, \nicefrac{7}{10}\}
        \end{array}\right.
    \end{equation*}
    Por lo que consideraremos:
    \begin{equation*}
        \Theta_0 = \{\nicefrac{5}{10}\}, \qquad \Theta_1 = \{\nicefrac{6}{10}, \nicefrac{7}{10}\}, \qquad \Theta = \{\nicefrac{5}{10}, \nicefrac{6}{10}, \nicefrac{7}{10}\}
    \end{equation*}
    Y tenemos $(X_1, X_2, X_3)$ una m.a.s. de $X$. Planteamos el test:
    \begin{equation*}
        \varphi(X_1, X_2, X_3) = \left\{\begin{array}{ll}
            1 & \text{si\ } X_1+X_2+X_3 \in \{2,3\} \\
            0 & \text{en otro caso\ } 
        \end{array}\right. 
    \end{equation*}
    Por la reproductividad de la binomial tenemos que $X_1+X_2+X_3\rightsquigarrow B(3,p)$. Calculamos: 
    \begin{description}
        \item [Tamaño del test.] 
            \begin{align*}
                \sup_{p\in \Theta_0} \beta_\varphi(p) &= \beta_\varphi(p_0) = E_{p_0}[\varphi] = P_{p_0}[X_1+X_2+X_3 = 2] + P_{p_0}[X_1 + X_2 + X_3 = 3] \\
                                                      &= P_{\nicefrac{1}{2}}[X_1+X_2+X_3 = 2] + P_{\nicefrac{1}{2}}[X_1 + X_2 + X_3 = 3]  \\
                                                      &= 0.375 + 0.125 = 0.5
            \end{align*}
        \item [Potencia frente a hipótesis alternativas.] 
            \begin{equation*}
                \sup_{p\in \Theta_1}\beta_\varphi(p) = \sup_{p \in \{\nicefrac{6}{10},\nicefrac{7}{10}\}} \beta_\varphi(p) = \max\{\beta_\varphi(\nicefrac{6}{10}), \beta_\varphi(\nicefrac{7}{10})\}
            \end{equation*}
            Calculamos cada una de ellas:
            \begin{itemize}
                \item Para $p = \nicefrac{6}{10}$:
                    \begin{align*}
                        \beta_\varphi(p) &= E_p[\varphi] = P_p[X_1 + X_2 + X_3 = 2] + P_p[X_1+X_2+X_3 = 3] \\
                                         &= P_{0.6}[X_1 + X_2 + X_3 =2] + P_{0.6}[X_1+X_2+X_3 =3]
                    \end{align*}
                    Si consideramos $Y \rightsquigarrow B(3,1-p) = B(3,\ 0.4)$ tenemos:
                    \begin{align*}
                        \beta_\varphi(p) &= P_{0.6}[X_1 + X_2 + X_3 =2] + P_{0.6}[X_1+X_2+X_3 =3] \\
                                         &= P[Y=3-2] + P[Y=3-3] = P[Y=1] + P[Y=0] \\
                                         &= 0.432 + 0.216 = 0.648
                    \end{align*}
                \item para $p=\nicefrac{7}{10}$:
                    \begin{align*}
                        \beta_\varphi(p) &= P_p[X_1 + X_2 + X_3 = 2] + P_p[X_1+X_2+X_3 = 3] \\
                                         &= P_{0.7}[X_1 + X_2 + X_3 =2] + P_{0.7}[X_1+X_2+X_3 =3]
                    \end{align*}
                    Si consideramos $Y\rightsquigarrow B(3,1-p) = B(3,\ 0.3)$ tenemos:
                    \begin{align*}
                        \beta_\varphi(p) &= P_{0.7}[X_1 + X_2 + X_3 =2] + P_{0.7}[X_1+X_2+X_3 =3] \\
                                         &= P[Y=1] + P[Y=0] = 0.441 + 0.343 = 0.784
                    \end{align*}
            \end{itemize}
            Por lo que la potencia será:
            \begin{equation*}
                \sup_{p\in \Theta_1}\beta_\varphi(p) = \max\{0.648, 0.784\} = 0.784
            \end{equation*}
    \end{description}
\end{ejercicio}

\begin{ejercicio}
    Sea $(X_1, \ldots, X_n)$ una muestra aleatoria simple de una variable aleatoria con distribución de Poisson de parámetro $\lm$. Encontrar el test más potente de tamaño $\alpha$ para resolver el problema de contraste
    \begin{align*}
        H_0 &: \lm = \lm_0 \\
        H_1 &: \lm = \lm_1
    \end{align*}
    \textit{Aplicación:} En una centralita telefónica el número de llamadas por minuto sigue una distribución de Poisson. Si en cinco minutos se han recibido 12 llamadas, ¿puede aceptarse que el número medio de llamadas por minuto es $1.5$, frente a que dicho número es 2, al nivel de significación $0.05$? Calcular la potencia del test obtenido.\\

    \noindent
    Sea $X\rightsquigarrow \cc{P}(\lm)$, en este caso tenemos:
    \begin{equation*}
        \Theta_0 = \{\lm_0\}, \qquad \Theta_1 = \{\lm_1\}, \qquad \Theta = \{\lm_0,\lm_1\}
    \end{equation*}
    Como nos encontramos ante un contraste simple frente a simple y queremos hayar el test más potente de tamaño $\alpha$, recurrimos a un test de Neymann-Pearson, que será de la forma:
    \begin{equation*}
        \varphi(X_1, \ldots, X_n) = \left\{\begin{array}{ll}
            1 & \text{si\ } \lm(X_1, \ldots, X_n) > k \\
             \gamma & \text{si\ } \lm(X_1, \ldots, X_n) = k \\
             0 & \text{si\ } \lm(X_1, \ldots, X_n) < k
        \end{array}\right. 
    \end{equation*}
    Para ciertos valores $\gamma\in [0,1]$, $k\in \mathbb{R}$ y una cierta función $\lm$ que nos disponemos a calcular. Primero observemos que:
    \begin{equation*}
        P_{\lm}[X_1 = x_1, \ldots, X_n = x_n] \stackrel{\text{iid.}}{=} \prod_{i=1}^{n} P_{\lm}[X=x_i] = \prod_{i=1}^{n} e^{-\lm} \frac{\lm^{x_i}}{x_i!} = e^{-n\lm} \cdot \frac{\lm^{\sum\limits_{k=1}^{n}x_i}}{\prod\limits_{i=1}^{n}x_i!} > 0
    \end{equation*}
    Por lo que:
    \begin{align*}
        \lm(x_1,\ldots, x_n) &= \frac{P_{\lm_1}[X_1=x_1,\ldots, X_n=x_n]}{P_{\lm_0}[X_1=x_1,\ldots, X_n=x_n]} = \frac{e^{-n\lm_1} \cdot \frac{\lm_1^{\sum\limits_{i=1}^{n}x_i}}{\prod\limits_{i=1}^{n}x_i!} }{e^{-n\lm_0} \cdot \frac{\lm_0^{\sum\limits_{i=1}^{n}x_i}}{\prod\limits_{i=1}^{n}x_i!} } = e^{n(\lm_0-\lm_1)} {\left(\frac{\lm_1}{\lm_0}\right)}^{\sum\limits_{i=1}^{n}x_i}
    \end{align*}
    Y para simplificar el test buscamos uno equivalente, si consideramos el estadístico $T(X_1, \ldots, X_n) = \sum\limits_{i=1}^{n}X_i\rightsquigarrow \cc{P}(n\lm)$, estudiamos el comportamiento de:
    \begin{equation*}
        g(t) = e^{n(\lm_0-\lm_1)}{\left(\frac{\lm_1}{\lm_0}\right)}^{t}
    \end{equation*}
    Para ello:
    \begin{gather*}
        \ln g(t) = n(\lm_0-\lm_1) + t\ln\left(\frac{\lm_1}{\lm_0}\right) \\
        g'(t) = \ln\left(\frac{\lm_1}{\lm_0}\right)
    \end{gather*}
    Y observamos que:
    \begin{equation*}
        g'(t) > 0 \Longleftrightarrow \ln\left(\frac{\lm_1}{\lm_0}\right) > 0 \Longleftrightarrow \frac{\lm_1}{\lm_0} > 1 \Longleftrightarrow \lm_1 > \lm_0
    \end{equation*}
    Por lo que distinguimos casos (sabemos que $\lm_0\neq \lm_1$):
    \begin{description}
        \item [Supuesto que $\lm_0<\lm_1$.] Tenemos entonces que $g$ es estrictamente creciente:

            \begin{figure}[H]
                \centering
                \begin{tikzpicture}
                    % Ejes
                    \draw[-Stealth] (-0.2,0) -- (3,0) node[right] {$T$};
                    \draw[-Stealth] (0,-0.2) -- (0,3) node[above] {$\lm$};

                    % Recta con pendiente negativa
                    \draw[thick] (0,0.65) -- (3,2.65);

                    % Punto c en el eje x
                    \coordinate (C) at (2,0);
                    \draw (C) node[below] {$c$};

                    % Proyección sobre la recta
                    \coordinate (K) at (2,2); % Ajustado para caer sobre la recta dibujada
                    \draw[dashed] (C) -- (K);
                    \draw[dashed] (K) -- (0,2);

                    % Etiqueta k en el eje y
                    \draw (0,2) node[left] {$k$};

                    % Punto en la recta
                    \fill (K) circle (2pt);
                \end{tikzpicture}
            \end{figure}
            Por tanto:
            \begin{equation*}
                \left.\begin{array}{l}
                    \lm > k \\
                    \lm = k \\
                    \lm < k
                \end{array}\right\} \Longleftrightarrow \left\{\begin{array}{l}
                    T > k \\
                    T = k \\
                    T < k 
                \end{array}\right.
            \end{equation*}
            De donde el test será:
            \begin{equation*}
                \varphi'(X_1, \ldots, X_n) = \left\{\begin{array}{ll}
                    1 & \text{si\ } \sum\limits_{i=1}^{n} X_i > c \\
                     \gamma& \text{si\ } \sum\limits_{i=1}^{n}X_i = c \\
                     0& \text{si\ } \sum\limits_{i=1}^{n}X_i < c
                \end{array}\right. 
            \end{equation*}
            Imponiendo tamaño $\alpha$:
            \begin{equation*}
                \alpha = \sup_{\lm \in \Theta_0}\beta_\varphi(\lm) = \beta_\varphi(\lm_0) = E_{\lm_0}[\varphi] = P_{\lm_0}[T > c] + \gamma P_{\lm_0}[T=c]
            \end{equation*}
            Y lo que haremos será para cierto $\alpha$ calcular los valores de $c$ y $\gamma$.
        \item [Supuesto que $\lm_1 < \lm_0$.] En este caso tendremos que $g$ es estrictamente decreciente:
            \begin{figure}[H]
                \centering
                \begin{tikzpicture}
                    % Ejes
                    \draw[-Stealth] (-0.2,0) -- (3,0) node[right] {$T$};
                    \draw[-Stealth] (0,-0.2) -- (0,3) node[above] {$\lm$};

                    % Recta con pendiente negativa
                    \draw[thick] (0,2.65) -- (3,0.65);

                    % Punto c en el eje x
                    \coordinate (C) at (1.5,0);
                    \draw (C) node[below] {$c$};

                    % Proyección sobre la recta
                    \coordinate (K) at (1.5,1.65); % Ajustado para caer sobre la recta dibujada
                    \draw[dashed] (C) -- (K);
                    \draw[dashed] (K) -- (0,1.65);

                    % Etiqueta k en el eje y
                    \draw (0,1.65) node[left] {$k$};

                    % Punto en la recta
                    \fill (K) circle (2pt);
                \end{tikzpicture}
            \end{figure}
            Por lo que obtendremos un test equivalente de la forma:
            \begin{equation*}
                \varphi'(X_1, \ldots, X_n) = \left\{\begin{array}{ll}
                    1 & \text{si\ } \sum\limits_{i=1}^{n}X_i<c \\
                     \gamma& \text{si\ } \sum\limits_{i=1}^{n}X_i = c \\
                     0 & \text{si\ } \sum\limits_{i=1}^{n}X_i > c
                \end{array}\right. 
            \end{equation*}
            Imponiendo tamaño $\alpha$:
            \begin{equation*}
                \alpha = \sup_{\lm \in \Theta_0}\beta_\varphi(\lm) = \beta_\varphi(\lm_0) = E_{\lm_0}[\varphi] = P_{\lm_0}[T < c] + \gamma P_{\lm_0}[T=c]
            \end{equation*}
            Y lo que haremos será para cierto $\alpha$ calcular los valores de $c$ y $\gamma$.
    \end{description}~\\

    \noindent
    \textit{Aplicación.} Sea:
    \begin{equation*}
        X \equiv \text{``Número de llamadas por minuto''}\rightsquigarrow\cc{P}(\lm)
    \end{equation*}
    En 5 observaciones $(x_1, \ldots, x_5)$ se ha obtenido:
    \begin{equation*}
        \sum_{i=1}^{n} x_i = 12
    \end{equation*}
    Y planteamos el contraste de hipótesis:
    \begin{equation*}
        \left\{\begin{array}{l}
            H_0 : \lm = 1.5 \\
            H_1 : \lm = 2
        \end{array}\right.
    \end{equation*}
    Sea $\alpha = 0.05$, como $\lm_0<\lm_1$ nos encontramos en el primer caso, por lo que usamos el test:
    \begin{equation*}
        \varphi'(X_1, \ldots, X_n) = \left\{\begin{array}{ll}
            1 & \text{si\ } \sum\limits_{i=1}^{n}X_i>c \\
             \gamma& \text{si\ } \sum\limits_{i=1}^{n}X_i = c \\
             0 & \text{si\ } \sum\limits_{i=1}^{n}X_i < c
        \end{array}\right. 
    \end{equation*}
    Imponiendo tamaño $\alpha$:
    \begin{equation*}
        0.05 = \alpha = \sup_{\lm \in \Theta_0}\beta_\varphi(\lm) = P_{\lm_0}[T > c] + \gamma P_{\lm_0}[T=c] = P_{1.5}[T>c] + \gamma P_{1.5}[T=c]
    \end{equation*}
    Recordamos que $T\rightsquigarrow \cc{P}(n\lm)$, y como nos encontramos bajo hipótesis nula, tenemos que $T\rightsquigarrow \cc{P}(5\cdot 1.5) \equiv \cc{P}(7.5)$. Buscamos el primer valor de $c$ de forma que se tenga $1-P[T\leq c] = P[T>c]\leq \alpha$:
    \begin{itemize}
        \item Para $c=12$, se tiene:
            \begin{equation*}
                P[T>c] = 0.0427 \leq 0.05 =  \alpha
            \end{equation*}
        \item Para $c=11$ se tiene que $P[T>c]$ es claramente mayor que $0.05$
    \end{itemize}
    Por lo que tomamos $c=12$. Calculamos ahora $\gamma$:
    \begin{equation*}
        0.05 = 0.0427 + \gamma \cdot 0.0366 \quad\Longrightarrow\quad \gamma = \frac{0.05-0.0427}{0.0366} \approx 0.199454
    \end{equation*}
    De esta forma, el test a usar es:
    \begin{equation*}
        \varphi'(X_1, \ldots, X_n) = \left\{\begin{array}{ll}
            1 & \text{si\ } \sum\limits_{i=1}^{n}X_i<12 \\
             0.199454 & \text{si\ } \sum\limits_{i=1}^{n}X_i = 12 \\
             0 & \text{si\ } \sum\limits_{i=1}^{n}X_i > 12
        \end{array}\right. 
    \end{equation*}
    Como $\sum\limits_{i=1}^{5} x_i = 12$, tenemos que:
    \begin{equation*}
        \varphi'(x_1, \ldots, x_5) = 0.199454
    \end{equation*}
    Por lo que rechazamos la hipótesis nula con dicha probabilidad. Lo mejor sería repetir el experimento para obtener una decisión clara. Calculamos ahora la potencia del test:
    \begin{equation*}
        \sup_{\lm \in \Theta_1}\beta_\varphi(\lm) = \beta_\varphi(\lm_1) = E_{\lm_1}[\varphi] = P_{\lm_1}[T>12] + 0.199454\cdot  P_{\lm_1}[T=12]
    \end{equation*}
    Recordemos que $T\rightsquigarrow \cc{P}(5\lm_1)\equiv \cc{P}(10)$:
    \begin{equation*}
        \sup_{\lm\in \Theta_1}\beta_\varphi(\lm) = P_2[T> 12] + 0.199454 \cdot P_2[T=12] = 0.227408
    \end{equation*}
\end{ejercicio}

\begin{ejercicio} % // TODO: HACER
    Dada una muestra de tamaño $n$ de una variable con distribución $\cc{N}(\mu, \sigma_0^2)$, deducir el test más potente de tamaño arbitrario para contrastar hipótesis simples sobre $\mu$.
\end{ejercicio}

\begin{ejercicio}% // TODO: HACER
    Dada una muestra de tamaño $n$ de una variable aleatoria con distribución $U(-\theta,\theta)$, deducir el test más potente de tamaño $\alpha$ para contrastar $H_0 : \theta = \theta_0$ frente a $H_1 : \theta = \theta_1$ y calcular su potencia. ¿Cuál es el test óptimo fijado un nivel de significación arbitrario?
\end{ejercicio}

\begin{ejercicio}% // TODO: HACER
    Deducir el test más potente de tamaño arbitrario para contrastar $h_0 : \theta = \theta_0$ frente a $H_1 : \theta = \theta_1$, basándose en una muestra de tamaño $n$ de una variable aleatoria con función de densidad
    \begin{equation*}
        f_\theta(x) = \frac{\theta}{x^2}, \qquad x>\theta
    \end{equation*}
    Deducir el test óptimo para un nivel de significación arbitrario.
\end{ejercicio}

\begin{ejercicio}% // TODO: HACER
    Construir el test de Neyman-Pearson de tamaño $\alpha$ para contrastar $H_0:\theta = \theta_0$ frente a $H_1 : \theta = \theta_1$, basándose en una muestra de tamaño $n$ de una variable aleatoria con función de densidad
    \begin{equation*}
        f_\theta(x) = \frac{1}{x\ln \theta}, \qquad 1<x<\theta
    \end{equation*}
    Deducir el test óptimo para un nivel de significación arbitrario.\\

    \noindent
    En este caso tenemos:
    \begin{equation*}
        \Theta_0 = \{\theta_0\}, \qquad \Theta_1 = \{\theta_1\}, \qquad \Theta = \{\theta_0,\theta_1\}
    \end{equation*}
    Sea $X$ una variable aleatoria cuya función de densidad es la enunciada y sea $(X_1, \ldots, X_n)$ una muestra aleatoria simple de la misma, el test de Neymann-Pearson de tamaño $\alpha$ para el contraste de hipótesis anunciadas será de la forma:
    \begin{equation*}
        \varphi(X_1, \ldots, X_n) = \left\{\begin{array}{ll}
            1 & \text{si\ } \lm(X_1, \ldots, X_n)>k \\
            \gamma & \text{si\ } \lm(X_1, \ldots, X_n) = k \\
            0 & \text{si\ } \lm(X_1, \ldots, X_n) < k 
        \end{array}\right. 
    \end{equation*}
    Para ciertas constantes $\gamma$ y $k$. Calculamos en primer lugar:
    \begin{align*}
        f_\theta^n(x_1, \ldots, x_n) &= \prod_{i=1}^{n} f_\theta(x_i) = \prod_{i=1}^{n} \frac{I_{\mathbb{R}^+}(x_{(1)}-1)I_{\mathbb{R}^-}(x_{(n)}-\theta)}{x_i \ln\theta} \\ &= {\left({(\ln\theta)}^{n} \prod\limits_{i=1}^{n}x_i\right)}^{-1}I_{\mathbb{R}^+}(x_{(1)}-1)I_{\mathbb{R}^-}(x_{(n)}-\theta)
    \end{align*}
    Y vemos que $f_\theta^n(x_1, \ldots, x_n) \neq 0 \Longleftrightarrow x_{(1)}>1 \land x_{(n)}<\theta$. Para dichas realizaciones muestrales calculamos:
    \begin{equation*}
        \lm(x_1, \ldots, x_n) = \frac{f_{\theta_0}^n(x_1, \ldots, x_n)}{f_{\theta_1}^n(x_1, \ldots, x_n)} = \frac{{(\ln\theta_{1})}^{n}\prod\limits_{i=1}^{n}x_i}{{(\ln\theta_0)}^{n}\prod\limits_{i=1}^{n}x_i} = {\left(\frac{\ln\theta_1}{\ln\theta_0}\right)}^{n}
    \end{equation*} % // TODO: TERMINAR
\end{ejercicio}

\begin{ejercicio}% // TODO: HACER
    Sea $X$ una observación de una variable aleatoria con función de densidad
    \begin{equation*}
        f_\theta(x) = \frac{1}{\theta} e^{\nicefrac{-x}{\theta}}, \qquad x>\theta
    \end{equation*}
    Construir el test de razón de verosimilitudes de tamaño $\alpha$ arbitrario para contrastar
    \begin{align*}
        H_0 &: \theta = \theta_0 \\
        H_1 &: \theta < \theta_1
    \end{align*}
\end{ejercicio}

\begin{ejercicio}
    En base a una observación de $X\rightsquigarrow \{B(n,p) : p\in \left]0,1\right[\}$, deducir el test de razón de verosimilitudes para contrastar la hipótesis de que el parámetro $p$ no supera un determinado valor, $p_0$.\\

    \noindent
    Planteamos el contraste de hipótesis:
    \begin{equation*}
        \left\{\begin{array}{l}
            H_0 : p\leq p_0 \\
            H_1 : p> p_0
        \end{array}\right.
    \end{equation*}
    Por lo que tendremos:
    \begin{equation*}
        \Theta_0 = \left]0,p_0\right], \qquad \Theta_1 = \left]p_0,1\right[, \qquad \Theta = \left]0,1\right[
    \end{equation*}
    Calculamos el EMV de $p$ para $x\in \cc{X}$:
    \begin{gather*}
        L_x(p) = P_p[X=x] = p^x {(1-p)}^{n-x} \quad\Longrightarrow\quad \ln L_x(p) = x\ln p + (n-x)\ln(1-p) \\
        \dfrac{\partial \ln L_x(p)}{\partial p} = \frac{x}{p} + \frac{x-n}{1-p} = \frac{x - xp + xp - np}{p(1-p)} = \frac{x-np}{p(1-p)} = 0 \Longleftrightarrow p = \frac{x}{n}
    \end{gather*}
    De esta forma:
    \begin{equation*}
        \sup_{p \in \Theta_0}L_x(p) = \left\{\begin{array}{ll}
            L_x(\nicefrac{x}{n}) & \text{si\ } p_0 \geq \nicefrac{x}{n}  \\
             L_x(p_0) & \text{si\ } p_0 < \nicefrac{x}{n}
        \end{array}\right. 
    \end{equation*}
    Por lo que:
    \begin{equation*}
        \lm(x) = \frac{\sup\limits_{p\in \Theta_0}L_x(p)}{\sup\limits_{p\in \Theta}L_x(p)} = \left\{\begin{array}{ll}
            1 & \text{si\ } p_0 \geq \nicefrac{x}{n}  \\
             \dfrac{L_x(p_0)}{L_x(\nicefrac{x}{n})}& \text{si\ } p_0<\nicefrac{x}{n}
        \end{array}\right. 
    \end{equation*}
    Y calculamos para el caso $p_0<\frac{x}{n}$ dicha fracción:
    \begin{equation*}
        \frac{L_x(p_0)}{L_x(\nicefrac{x}{n})} = \frac{p_0^x {(1-p_0)}^{n-x}}{{\left(\frac{x}{n}\right)}^{x}{\left(1-\frac{x}{n}\right)}^{n-x}} = {\left(\frac{np_0}{x}\right)}^{x} {\left(\frac{1-p_0}{1-\frac{x}{n}}\right)}^{n-x}
    \end{equation*}
    Y tratamos de ver si es creciente o decreciente en función de $x$, para lo que consideramos:
    \begin{gather*}
        g(x) = {\left(\frac{np_0}{x}\right)}^{x} {\left(\frac{1-p_0}{1-\frac{x}{n}}\right)}^{n-x}  \\
        \ln g(x) = x \ln (np_0) - x\ln x + (n-x)\ln (1-p_0) - (n-x)\ln \left(1-\frac{x}{n}\right) \\
        \dfrac{\partial \ln g(x)}{\partial  x} = \ln(np_0) - \ln x \cancel{- 1} - \ln(1-p_0) + \ln\left(1-\frac{x}{n}\right) \cancel{+1} = \ln\left(\frac{np_0}{x}\right) + \ln\left(\frac{1-\frac{x}{n}}{1-p_0}\right)
    \end{gather*}
    Para el primer sumando:
    \begin{equation*}
        p_0 < \frac{x}{n} \Longleftrightarrow np_0 < x \Longleftrightarrow \frac{np_0}{x}<1 \Longleftrightarrow \ln\left(\frac{np_0}{x}\right) < 0
    \end{equation*}
    Para el segundo:
    \begin{equation*}
        p_0 < \frac{x}{n}\Longleftrightarrow -p_0 > -\frac{x}{n} \Longleftrightarrow 1-p_0>1-\frac{x}{n} \Longleftrightarrow \frac{1-\frac{x}{n}}{1-p_0} < 1 \Longleftrightarrow \ln\left(\frac{1-\frac{x}{n}}{1-p_0}\right) < 0
    \end{equation*}
    Por tanto tenemos que $g$ es estrictamente decreciente, de donde si consideramos $\lm$ como función de $x$ ($p_0 \geq \nicefrac{x}{n} \Longleftrightarrow x \leq np_0$):
    \begin{figure}[H]
        \centering
        \begin{tikzpicture}
            % Ejes
            \draw[-Stealth] (-0.2,0) -- (6,0) node[right] {$x$};
            \draw[-Stealth] (0,-0.2) -- (0,3.5) node[left] {$\lm$};

            % Recta con pendiente negativa
            \draw[thick] (3,2.65) -- (6,0.65);
            \draw[thick] (0,2.65) -- (3,2.65);

            % Punto c en el eje x
            \coordinate (C) at (4.5,0);
            \draw (C) node[below] {$k$};

            % Proyección sobre la recta
            \coordinate (K) at (4.5,1.65); % Ajustado para caer sobre la recta dibujada
            \draw[dashed] (C) -- (K);
            \draw[dashed] (K) -- (0,1.65);

            \draw[dashed] (3,0) -- (3,2.65);
            \draw (3,0) node[below] {$np_0$};

            % Etiqueta k en el eje y
            \draw (0,1.65) node[left] {$c$};
            \draw (0,2.65) node[left] {$1$};

            % Punto en la recta
            \fill (K) circle (2pt);
        \end{tikzpicture}
    \end{figure}
    \noindent
    Tendremos que:
    \begin{equation*}
        \left.\begin{array}{l}
            \lm < c \\
            \lm \geq c
        \end{array}\right\} \Longleftrightarrow \left\{\begin{array}{l}
            x > k \\
            x \leq k
        \end{array}\right. \qquad \text{con\ } k\geq np_0
    \end{equation*}
    Por lo que el test a considerar será:
    \begin{equation*}
        \varphi(X) = \left\{\begin{array}{ll}
            1 & \text{si\ } X>k \\
             0 & \text{si\ } X\leq k
        \end{array}\right. 
    \end{equation*}
    Y determinaremos el valor de $k$ imponiendo un nivel de significación $\alpha$:
    \begin{equation*}
        \alpha \geq \sup_{p\in \Theta_0}\beta_\varphi(p) = \sup_{p\in \Theta_0} E_p[\varphi] = \sup_{p\in \Theta_0} P_p[X>k] = \sup_{p\in \Theta_0} \left(\sum_{t=\lfloor k \rfloor+1}^{n} P_p[X=t] \right)
    \end{equation*} 
    Veamos ahora que fijado $t\in \{\lfloor k\rfloor+1,\ldots,n\}$ se tiene que $P_p[X=t]$ es creciente en función de $p\in \Theta_0$. Para ello, si tomamos:
    \begin{gather*}
        h(p) = P_p[X=t] = p^t {(1-p)}^{n-t} \quad\Longrightarrow\quad \ln h(p) = t\ln p + (n-t)\ln (1-p) \\
        \dfrac{\partial \ln h(p)}{\partial p} = \frac{t-np}{p(1-p)}
    \end{gather*}
    Observamos ahora que:
    \begin{equation*}
        t > \lfloor k\rfloor +1 > k \geq np_0 \geq np 
    \end{equation*}
    De donde deducimos que $h(p)$ es creciente, por lo que el supremo anterior se alcanza en $p_0$:
    \begin{equation*}
        \alpha \geq \sup_{p\in \Theta_0}\beta_\varphi(p) = \sup_{p\in \Theta_0} \left(\sum_{t=\lfloor k \rfloor+1}^{n} P_p[X=t] \right) = \sum_{t=\lfloor k \rfloor +1}^{n} P_{p_0}[X=t]
    \end{equation*} 
    En un caso concreto de esta fórmula se despeja el valor de $k$.
\end{ejercicio}

\begin{ejercicio}
    Sea $X$ una variable con función de densidad
    \begin{equation*}
        f_\theta(x) = \theta x^{\theta-1}, \qquad 0<x<1
    \end{equation*}
    Basándose en una observación de $X$, deducir el test de razón de verosimilitudes de tamaño arbitrario para contrastar
    \begin{align*}
        H_0 &: \theta \leq \theta_0 \\
        H_1 &: \theta > \theta_1
    \end{align*}~\\

    \noindent
    Tendremos:
    \begin{equation*}
        \Theta_0 = \left]0,\theta_0\right], \qquad \Theta_1 = \left]\theta_0,+\infty\right[, \qquad \Theta = \mathbb{R}^+
    \end{equation*}
    Calculamos el EMV de $\theta$ para $x\in \cc{X}$:
    \begin{gather*}
        L_x(\theta) = f_\theta(x) = \theta x^{\theta-1} \quad\Longrightarrow\quad \ln L_x(\theta) = \ln\theta + (\theta-1)\ln x \\
        \frac{\partial  \ln L_x(\theta)}{\partial \theta} = \frac{1}{\theta} + \ln x = 0 \Longleftrightarrow \theta = \frac{-1}{\ln x}
    \end{gather*}
    Y observemos que como $x\in \left]0,1\right[$ tenemos que $\ln x < 0$. El EMV es $\hat{\theta} = \nicefrac{-1}{\ln X}$. Por tanto:
    \begin{equation*}
        \sup_{\theta\in \Theta_0} L_x(\theta) = \left\{\begin{array}{ll}
            L_x(\nicefrac{-1}{\ln x}) & \text{si\ } \theta_0 \geq \nicefrac{-1}{\ln x} \\
             L_x(\theta_0)& \text{si\ } \theta_0 < \nicefrac{-1}{\ln x}
        \end{array}\right. 
    \end{equation*}

    de donde:
    \begin{equation*}
        \lm(x) = \dfrac{\sup\limits_{\theta\in \Theta_0}L_x(\theta)}{\sup\limits_{\theta\in \Theta}L_x(\theta)} = \left\{\begin{array}{ll}
            1 & \text{si\ } \theta_0 \geq \nicefrac{-1}{\ln x} \\
              \dfrac{L_x(\theta_0)}{L_x(\nicefrac{-1}{\ln x})}& \text{si\ } \theta_0 < \nicefrac{-1}{\ln x}
        \end{array}\right. 
    \end{equation*}
    En el caso $\theta_0 < \frac{-1}{\ln x}$:
    \begin{equation*}
        \dfrac{L_x(\theta_0)}{L_x(\nicefrac{-1}{\ln x})} = \dfrac{\theta_0 x^{\theta_0-1}}{\frac{-1}{\ln x}x^{\left(\frac{-1}{\ln x}-1\right)}} = -\theta_0 \ln x \cdot x^{\theta_0 + \frac{1}{\ln x}}
    \end{equation*}
    Y veamos si en este caso $\lm$ es creciente o decreciente en función de $x$. Para ello, consideramos:
    \begin{gather*}
        g(x) =  -\theta_0 \ln x \cdot x^{\theta_0 + \frac{1}{\ln x}}  \\
        \ln g(x) = \ln(-\theta_0 \ln x) + \left(\theta_0 + \frac{1}{\ln x}\right)\ln x = \ln(\theta_0) + \ln(-\ln x) + \theta_0 \ln x + 1 \\
        \dfrac{\partial \ln g(x)}{\partial  x} = \frac{-1}{x\ln x} + \frac{\theta_0}{x} = \frac{-1 + \theta_0 \ln x}{x\ln x} < 0 \qquad (x\in \left]0,1\right[ )
    \end{gather*}
    Por lo que $g$ es estrictamente decreciente, de donde si vemos $\lm$ como función de $x$ ($\theta_0 \geq \nicefrac{-1}{\ln x} \Longleftrightarrow \ln x \leq \nicefrac{-1}{\theta_0} \Longleftrightarrow x \leq e^{\nicefrac{-1}{\theta_0}}$):
    \begin{figure}[H]
        \centering
        \begin{tikzpicture}
            % Ejes
            \draw[-Stealth] (-0.2,0) -- (6,0) node[right] {$x$};
            \draw[-Stealth] (0,-0.2) -- (0,3.5) node[left] {$\lm$};

            % Recta con pendiente negativa
            \draw[thick] (3,2.65) -- (6,0.65);
            \draw[thick] (0,2.65) -- (3,2.65);

            % Punto c en el eje x
            \coordinate (C) at (4.5,0);
            \draw (C) node[below] {$k$};

            % Proyección sobre la recta
            \coordinate (K) at (4.5,1.65); % Ajustado para caer sobre la recta dibujada
            \draw[dashed] (C) -- (K);
            \draw[dashed] (K) -- (0,1.65);

            \draw[dashed] (3,0) -- (3,2.65);
            \draw (3,0) node[below] {$e^{\nicefrac{-1}{\theta_0}}$};

            % Etiqueta k en el eje y
            \draw (0,1.65) node[left] {$c$};
            \draw (0,2.65) node[left] {$1$};

            % Punto en la recta
            \fill (K) circle (2pt);
        \end{tikzpicture}
    \end{figure}
    \noindent
    Tenemos entonces que:
    \begin{equation*}
        \left.\begin{array}{l}
            \lm < c \\
            \lm \geq c
        \end{array}\right\} \Longleftrightarrow \left\{\begin{array}{l}
            x > k \\
            x \leq k
        \end{array}\right. \qquad \text{con}\quad  k\geq e^{\nicefrac{-1}{\theta_0}}
    \end{equation*}
    Y el test a considerar será:
    \begin{equation*}
        \varphi(X) = \left\{\begin{array}{ll}
            1 & \text{si\ } X>k \\
            0 & \text{si\ } X\leq k
        \end{array}\right. 
    \end{equation*}
    y determinamos el valor de $k$ imponiendo tamaño $\alpha$:
    \begin{align*}
        \alpha &= \sup_{\theta\in \Theta_0}\beta_\varphi(\theta) = \sup_{\theta\in \Theta_0} E_\theta[\varphi] = \sup_{\theta\in \Theta_0} P_\theta[X>k] = \sup_{\theta\in \Theta_0}\left( \int_{k}^{1} \theta t^{\theta-1}~dt  \right) \\
               &= \sup_{\theta\in \Theta_0}\left([t^{\theta}]_k^1\right) = \sup_{\theta\in \Theta_0}(1-k^\theta) \stackrel{(k\in [0,1])}{=} 1-k^{\theta_0}
    \end{align*}
    Luego:
    \begin{equation*}
        k^{\theta_0} = 1-\alpha \quad\Longrightarrow\quad \ln k = \frac{\ln (1-\alpha)}{\theta_0} \quad\Longrightarrow\quad k = e^{\ln\left({(1-\alpha)}^{\frac{1}{\theta_0}}\right)} = {(1-\alpha)}^{\frac{1}{\theta_0}}
    \end{equation*}
\end{ejercicio}

\begin{ejercicio}% // TODO: HACER
    Un fabricante de coches asegura que la distancia media recorrida con un galón de gasolina es al menos 30 millas. Probados 9 coches de esta fábrica, la distancia media recorrida con un galón de gasolina ha sido 26 millas, y la suma de los cuadrados 6106 millas al cuadrado.
    \begin{enumerate}[label=\alph*)]
        \item Suponiendo que la distancia recorrida por estos coches con un galón de gasolina tiene distribución normal, contrastar la hipótesis del fabricante a partir de estos datos, a nivel de significación $0.01$.
        \item ¿Qué conclusión se obtendría de estos mismos datos, al mismo nivel de significación, si se sabe que la desviación típica de la variable considerada es $5.5$?
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}% // TODO: HACER
    Un fabricante de baterías asegura que la desviación típica del tiempo de vida de las mismas es, a lo sumo, 70 horas. Una muestra de 26 baterías tomadas al azar ha dado una cuasidesviación típica de 84 horas. Haciendo las hipótesis adecuadas de normalidad, ¿proporcionan los datos evidencia para rechazar la hipótesis del fabricante al nivel $0.02$?
\end{ejercicio}

\begin{ejercicio}
    Un profesor asegura que tiene un nuevo método de enseñanza mejor que el usado tradicionalmente. Para comprobar si tiene razón se selecciona de forma aleatoria e independiente dos grupos de alumnos, $A$ y $B$, utilizándose el nuevo método con el grupo $A$ y el tradicional con el $B$. $A$ final de curso se hace un examen a los alumnos, obteniéndose las siguientes puntuaciones:\newline
    Grupo $A$: 6, 5, 4, 7, 3, $5.5$, 6, 7, 6.\newline
    Grupo $B$: 5, 4, 5, 6, 4, 6, 5, 3, 7.\newline
    Supuesto que las puntuaciones de cada grupo tienen distribución normal, ¿proporcionan estos datos evidencia para rechazar el nuevo método a nivel de significación $0.05$?\\

    \noindent
    Si notamos a las poblaciones enunciadas por (suponemos que tienen la misma varianza) $X\rightsquigarrow \cc{N}(\mu_1, \sigma^2)$, $Y\rightsquigarrow\cc{N}(\mu_2,\sigma^2)$ obteniendo muestras de tamaño 9 de cada una de ellas: $(x_1, \ldots, x_9)$ (grupo A) y $(y_1,\ldots,y_9)$ (grupo B) (tenemos $n_1=n_2=9$). Planteamos el contraste de hipótesis:
    \begin{equation*}
        \left\{\begin{array}{l}
            H_0 : \mu_1-\mu_2\geq 0 \\
            H_1 : \mu_1-\mu_2< 0 \\
        \end{array}\right.
    \end{equation*}
    En teoría vimos que se rechaza la hipótesis nula si:
    \begin{equation*}
        |t_{exp}| >t_{n_1+n_2-2;\nicefrac{\alpha}{2}}
    \end{equation*}

    donde:
    \begin{equation*}
        t_{exp} = \frac{\overline{x}-\overline{y}}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}, \qquad s_p = \sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}
    \end{equation*}
    Calculamos para ello:
    \begin{itemize}
        \item $n_1 = n_2 = 9$.
        \item $\overline{x} = 5.5$.
        \item $s_1^2 = 1.75$.
        \item $\overline{y} = 5$.
        \item $s_2^2 = 1.5$.
    \end{itemize}
    Por lo que:
    \begin{equation*}
        s_p = \sqrt{\frac{8\cdot 1.75 + 8\cdot 1.5}{9+9-2}} \approx 1.274755, \qquad 
        t_{exp} = \frac{5.5 - 5}{1.274755\cdot \sqrt{\frac{2}{9}}} \approx 0.83205
    \end{equation*}
    Y si calculamos ahora $t_{n_1+n_2-2;\nicefrac{\alpha}{2}}$:
    \begin{equation*}
        t_{n_1+n_2-2;\nicefrac{\alpha}{2}} = t_{9+9-2;\nicefrac{0.05}{2}} = t_{16;0.025} = 2.1199
    \end{equation*}
    Como $t_{exp}$ no está dentro de la región crítica, los datos no proporcionan evidencia para rechazar el nuevo método a nivel de significación $0.05$.
\end{ejercicio}

\begin{ejercicio}
    A partir de las siguientes observaciones de muestras independientes de dos poblaciones normales, contrastar, al nivel de significación $0.01$, si la media de la primera población supera en al menos una unidad la media de la segunda.\newline
    Muestra 1: 132, 139, 126, 114, 122, 132, 141, 126.\newline
    Muestra 2: 124, 141, 118, 116, 114, 132, 145, 123, 121.\\

    \noindent
    Planteamos el constrate de hipótesis:
    \begin{equation*}
        \left\{\begin{array}{l}
            H_0 : \mu_1-\mu_2 \geq \mu_0 = 1 \\
            H_1 : \mu_1-\mu_2 < \mu_0
        \end{array}\right.
    \end{equation*}
    Sean $X\rightsquigarrow \cc{N}(\mu_1, \sigma^2)$, $Y\rightsquigarrow\cc{N}(\mu_2,\sigma^2)$, tenemos dos observaciones: $(x_1, \ldots, x_8)$ de $X$ y $(y_1, \ldots, y_9)$ de $Y$ (tomamos $n_1=8$ y $n_2 = 9$). Usaremos el estadístico:
    \begin{equation*}
        T = \frac{\overline{X}-\overline{Y}-(\mu_1-\mu_2)}{S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}\rightsquigarrow t_{n_1+n_2-2} , \qquad S_p = \sqrt{\frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1+n_2-2}}
    \end{equation*}
    Por lo que calculamos $t_{exp}$: 
    \begin{equation*}
        t_{exp} = \frac{\overline{x}-\overline{y}-\mu_0}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}
    \end{equation*}

    para lo que necesitaremos:
    \begin{equation*}
        \overline{x} = 129, \qquad \overline{y} = 126, \qquad s_1^2 = 79.142857, \qquad s_2^2 = 121
    \end{equation*}
    Por lo que:
    \begin{gather*}
        s_p = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}} = \sqrt{\frac{7\cdot 79.142857 + 8\cdot 121}{8+9-2}}  \approx 10.073066 \\
        t_{exp} = \frac{\overline{x}-\overline{y}-\mu_0}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} = \frac{129 - 126 -1}{10.073066 \sqrt{\frac{1}{8} + \frac{1}{9}}} \approx 0.408611
    \end{gather*}
    Sea $\alpha = 0.01$, vimos en teoría que la región crítica era:
    \begin{equation*}
        t_{exp} < -t_{n_1+n_2-2;\alpha} = -t_{15;0.01} = 2.6025
    \end{equation*}
    Por tanto, como $0.408611 < 2.6025$ estamos en la región crítica, por lo que podemos rechazar a nivel de significación $0.01$ que la media de la primera población supera en al menos una unidad la media de la segunda.
\end{ejercicio}

\begin{ejercicio}% // TODO: HACER
    Una central lechera recibe diariamente leche de dos granjas $A$ y $B$. Para comparar la calidad de los productos recibidos se ha medido el contenido en grasa en muestras de leche tomadas al azar de cada una de las granjas, con los siguientes resultados:
    \begin{table}[H]
    \centering
    \begin{tabular}{c|cccccc}
     & \multicolumn{6}{c}{Contenido en grasa $(\%)$} \\
     \hline
        Granja A & 14 & 12 & 15 & 15 & 11 & 16 \\
        Granja B & 20 & 18 & 18 & 19 & 15 &
    \end{tabular}
    \end{table}
    \begin{enumerate}[label=\alph*)]
        \item ¿Puede suponerse, a nivel de significación $0.05$, que el contenido medio en grasa de la leche de las dos granjas es el mismo? Especificar las hipótesis bajo las que se resuelve este problema.
        \item Calcular un intervalo de confianza, a nivel de confianza $0.9$, para la varianza del contenido en grasa de la leche de la granja B. A partir de dicho intervalo, deducir si puede aceptarse que la varianza de esta población es igual a 3. Especificar el problema de contraste y el test utilizado; calcular su tamaño.
    \end{enumerate}
\end{ejercicio}

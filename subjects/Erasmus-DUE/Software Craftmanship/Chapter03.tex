\chapter{Test Driven Development}

This chapter covers the concept of \emph{Testing}. Given that the goal of a developper is achieving clean code that \emph{works}, testing is a crucial part of the development process. There are however two main approaches to testing: \emph{Debug-Later Development} and \emph{Test Driven Development}. The first one is the most common, but the second one is the one that leads to better code quality. We will see in this chapter why that is the case, and how to implement TDD in practice.

\section{Debug-Later Development}

As the name suggests, Debug-Later Development is the approach where developers write code without testing it, and then debug it later when it doesn't work. The problem is that a new bug may be found at any time, forcing us to go back and forth between writing code and debugging it. In order to explain this concept, the following time definitions are used:
\begin{itemize}
    \item \ul{Time till discovery ($T_d$)}: the time it takes for a bug to be discovered since it was introduced.
    \item \ul{Time till found ($T_{\text{find}}$)}: the time it takes for the reason for the bug to be found since it was discovered.
    \item \ul{Time till fixed ($T_{\text{fix}}$)}: the time it takes for the bug to be fixed since its reason was found.
\end{itemize}

This approach has several disadvantages:
\begin{itemize}
    \item $T_d$ and $T_{\text{find}}$ are usually very long, because the code is not tested until it is complete, and the bug may be found at any time.
    \item The longer a bug is present in the code, the more likely it is to cause other bugs and the harder it is to fix it. Therefore, $T_{\text{fix}}$ is also usually very long.
    \item Clean code is harder to achieve, because developers are more focused on making the code work than on making it clean.
    \item Testing is usually forgotten or neglected, as developpers think that their code works, and they don't want to spend time writing tests for it.
\end{itemize}

This is the reason why Debug-Later Development is not a good approach, and why Test Driven Development is a better alternative.

\section{Test Driven Development}

Test Driven Development (TDD) is a development discipine (not a testing technique) where developers write tests before writing the code that makes the tests pass. It helps sequentially focus individually on working code and clean code, and it leads to better code quality. 

\subsection{The Three Laws of TDD}

The Test Driven Development process is based on three laws, which garantee that the code is always tested:
\begin{itemize}
    \item \ul{First Law}: You are not allowed to write any production code unless it is to make a failing unit test pass.    
    \item \ul{Second Law}: You may not write more of a unit test than is sufficient to fail, and not compiling is failing.
    
    This way, as soon as the new test fails, you must stop writing the test and start writing the production code to make it pass. In addition, as there is no production code yet, not compiling will happen very soon.
    \item \ul{Third Law}: You may not write more production code than is sufficient to pass the currently failing test.    
\end{itemize}

This leads to three main beneficts. Firstly, only what is strictly necessary is coded. Secondly, bugs are found and fixed as soon as they are introduced ($T_d$, $T_{\text{find}}$ and $T_{\text{fix}}$ are reduced), which makes them easier to fix. Finally, tiny steps are always made towards the goal, which makes it easier to achieve clean code.

\subsection{The TDD Microcycle}

The TDD process can be summarized in a microcycle, which is a sequence of steps that are repeated every few minutes until the code is complete:
\begin{enumerate}
    \item Write a small test (as small as possible).
    \item Compile all the tests and see that the new test does not compile.
    \item Write the production code to make the test compile.
    \item Compile all the tests and see that the new test fails.
    
    We should not assume that the test fails, as it may pass for the wrong reason (for example, if the test is not written correctly). If we assume that the test fails, we may code with a false sense of security.
    \item Write the production code to make the test pass.
    \item Compile all the tests and see that they \emph{all} pass. It is important to check that all the tests pass, because the new code may have broken some existing code.
    \item Refactor the code in order to make it cleaner.
    \item Compile all the tests again and see that they all pass.
\end{enumerate}

Regarding refactoring, it is the process of changing the code without changing its behavior. It can be risky, as it can introduce new bugs, so it should not be done until all the tests pass.

\section{Testing}

As explained before, testing is a crucial part of the development process, as they help us feel confident that our code works and it reduces the developers' stress. However, they are not easy at all, as they require a lot of practice and experience to be good at writing tests. In addition, it should be noted that tests \emph{are also code}. They must be designed, written, refactored and maintained just like production code.

\subsection{Red Bar Patterns}

A red bar represents a failing test; so a red bar pattern is a pattern that leads to a failing test; which is what should be done according to the microcycle of TDD. There are some common red bar patterns that should be followed:
\begin{itemize}
    \item \ul{List of Future Tests}: a list of tests that should be written in the future should be written. It lets us focus on one test at a time, and it helps us keep track of the tests that we want to write. It should not be a fixed list, as it may change as we write the code and discover new things.
    \item \ul{Picking the Next Test}: One that can easily be made to pass should be picked. This way, we can make progress quickly and feel good about it, which motivates us to keep going. If none applies, an existing bigger test can be split into smaller tests (which should also be added to the list of future tests).
    
    It is also important to note that a passing test provides an assertion. Therefore, tests that allow to assume things that will be useful for future tests should be picked, as they will make it easier to write the future tests.

    \item \ul{Adding Tests}: Test should be added to the list of future tests for several reasons: when a potencial problem is introduced, when a bug is reported, when a big test is split into smaller tests... However, it should not be forgotten that the list may eventually be finished.
    
    \item \ul{Removing Tests}: The list of future tests should be reviewed regularly, and tests that are no longer relevant should be removed, as more tests does not necessarily mean better testing.
    
    If a test can be made fail individually, it should be kept, as it tests something that is not tested by other tests. However, if a test cannot be made fail individually, it may be testing something that is already tested by other tests, and its deletion may be considered.
\end{itemize}

There are two more aspects that should be taken into account regarding red bar patterns: what to do when stuck, and how to end the programming session.
\begin{itemize}
    \item \ul{When Stuck}: if we are stuck, our first attempt should be to take a short break, as it may help us clear our mind and see the problem from a different perspective. If we are still lost after the break, throwing away the code and starting over may be a good idea, as it allows us to start fresh and avoid getting stuck in a dead end.
    
    Another good idea is to switch partners in pair programming, as it forces us to explain our code to the new partner, which may help us see the problem from a different perspective. In addition, the new partner is not emotionally invested in prior decisions, which may make it easier to throw away the code and start over if necessary.
    
    \item \ul{Ending the Programming Session}: when it comes to ending the programming session:
    \begin{itemize}
        \item If we program alone, we should end the session with the last test failing, so that we know where to start the next session.
        \item If we program in teams, we should end the session with all the tests passing, so that we can leave the code in a good state for the next person.
    \end{itemize}
\end{itemize}

\subsection{Green Bar Patterns}

A green bar represents a passing test; so a green bar pattern is a pattern that leads to a passing test. There are some common green bar patterns that should be followed:
\begin{itemize}
    \item \ul{Obvious Implementation}: the simplest implementation that makes the test pass should be written.
    \item \ul{Fake it ('til you make it)}: if the test is hard to make pass, a fake implementation (maybe returning a hardcoded value) can be written to make the test pass, and then it can be refactored to a real implementation.
    
    However, it is important to make sure that you have a test that will force you to look at the fake implementation again, if not, you should add it to your list of future tests.
    \item \ul{Triangulation}: if you don't know how to code the implementation, wait until you have two or more tests. In that case, you should use the \emph{Rule of Thumb}: fake it until it is more trouble to fake it than to make it. Therefore, when you can no longer fake it, you should code the implementation, as you will have enough information to do it.
\end{itemize}

\subsection{Testing Patterns}

Some good testing principles that should be followed are:
\begin{itemize}
    \item \ul{Small Tests}: tests should be small. A test should one fail for one reason, and it should be easy to understand why it fails.
    \item \ul{Always rerun all the tests}: all the tests should be rerun after every change, as we may have broken something without realizing it.
    \item \ul{Tests should fail}: if a bug is intentionally introduced, a test should fail.
    \item \ul{Tests should fail independently}: ideally, each test should be able to fail independently of the others. If a lot of tests fail at the same time, it may be hard to understand why they fail and to fix the problem. It could also mean that the tests are not well designed, as they may be testing too much at the same time, or they may be redundant.
    \item \ul{Do not debug}: in case of a failing test, if we can fix it without debugging, we should do it, as it is faster and it helps us keep the flow. However, if we cannot fix it directly, it is faster to go back (using VCS).
    \item \ul{Tests for external software}: if we are using external software (for example, a database), we should write tests for it, as it may have bugs that affect our code.
    \item \ul{Test Private Methods through Public Methods}: private methods should not be tested directly, as they are implementation details that may change. Instead, they should be tested through public methods that use them.
    \item \ul{Test Error Cases}: tests should not only cover the correct cases, but also the errors. It should be checked that the errors are reported and handled correctly. With this aim, crash test dummies (explained in the following subsection) can be used.
    \item \ul{Test Should be Fast}: tests should be fast, as they will be run frequently. If tests are slow, we may be tempted to run them less frequently (which is not desired). Posible ways to make tests faster are mocking external software (explained in the following subsection) or removing unnecessary tests.
    \item \ul{Test Unit Behavior}: tests should not necessarily test the whole class, but they should test the behaviors of the unit. The tests' name should reflect the behavior that they are testing.
    \item \ul{Legacy Code}: if we have legacy code (code without tests), there are two possible approaches to add tests to it:
    \begin{itemize}
        \item If you can add unit tests directly, do it but just testing its current behavior (not caring about if it's correct or not).
        \item If you cannot add unit tests directly, start from the outside to the inside: start from the outside (whole system tests), use them to write integration tests, and then use them to write unit tests.
    \end{itemize}
    This way, you will have a safety net to refactor the code and add more tests later.
\end{itemize}

There is one more aspect that should be taken into account, mocking.
\subsubsection{Mocking}

Mocking is the process of replacing a real object with a fake one that simulates its behavior. It is useful when we want to test a unit that depends on an external software (for example, a database), or when we want to test a unit that is not yet implemented.

Mocking is in fact a \emph{slang} term for \emph{test double}, which is a more general term that includes different types of fake objects:
\begin{itemize}
    \item \ul{Test Dummy}: an object that is passed around but never actually used (only used to satisfy the compiler).
    \item \ul{Test Stub}: an object that provides predefined answers to method calls.
    \item \ul{Crash Test Dummy}: special stub that return errors (throws exceptions) when called. It is mainly used to test error handling.
    \item \ul{Exploding Fake}: an object that causes test failure if it is called. It is mainly used to test that a method is not called when it should not be.
    \item \ul{Test Spy}: special stub that records information about how it was called, which functions were called, with what parameters, how many times... 
    \item \ul{Mock Object}: more complex spy that also includes assertions about how it should be called.
    \item \ul{Fake Object}: an object that has a working implementation, but it is not suitable for production (for example, an in-memory database).
\end{itemize}

When injecting a test double, they should not be injected directly, as it may make the code more complex and less maintainable. Instead, they should be injected as a reference to the class. Therefore, the test double can be passed when testing, and the real object can be passed when running the code in production.

Mocking has several advantages, as it allows us to test units that depend on external software, and it allows us to test units that are not yet implemented. It also allows for faster tests. Therefore, a common mistake is thinking that every dependency should be mocked, but that can lead to slower tests and explosion of polymorphism (for dependency injection). Therefore, the ``Uncle Bob's Mocking Heuristic'' should be followed: mock across architecturally significant boundaries, but not within those boundaries.
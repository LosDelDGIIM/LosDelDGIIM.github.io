\subsection{Relación 2}
\setcounter{ejercicio}{0}

\begin{ejercicio}
    Dado el problema de valores iniciales
    \begin{equation*}
        \begin{cases}
            x'(t) = f(t, x(t)) \\
            x(a) = \mu
        \end{cases}
    \end{equation*}
    se pretende utilizar el siguiente método numérico para estimar el valor de $x(b)$, con $b > a$:
    \begin{equation*}
        x_{n+1} = x_n + h \left( \alpha f(t_n, x_n) + (1 - \alpha) f(t_{n+1}, x_{n+1}) \right), \quad \alpha \in [0, 1]
    \end{equation*}
    \begin{enumerate}
        \item ¿Podemos asegurar que el método es estable? Estudia su consistencia y su convergencia.
        
        Su polinomio característico es:
        \begin{equation*}
            p(\lm) = \lm -1
        \end{equation*}

        Por lo tanto, la única raíz es $\lm = 1$, que es simple y tiene módulo 1. Por tanto, el método es estable.
        Respecto a la consistencia, necesitamos que:
        \begin{itemize}
            \item $p(1) = 0$, que se tiene.
            \item $\Phi(x(t_n), x(t_n), t_n, 0) = p'(1)f(t_n, x(t_n))$:
            \begin{equation*}
                \Phi(x(t_n), x(t_n), t_n, 0) = \alpha f(t_n, x(t_n)) + (1 - \alpha) f(t_n, x(t_n))
                = f(t_n, x(t_n)) = p'(1)f(t_n, x(t_n))
            \end{equation*}
        \end{itemize}

        Por lo tanto, el método es consistente. Por último, como es consistente y estable, es convergente.
        \item Si sabemos que la función $f$ es lipschitziana respecto a la segunda variable con constante de Lipschitz $L$, ¿cuánto debe valer $h$ como máximo para que la ecuación tenga solución para cualquier valor de $n$?\\
        
        Definimos la función $g$ como:
        \Func{g}{\bb{R}}{\bb{R}}{x}{x_n + h \left( \alpha f(t_n, x_n) + (1 - \alpha) f(t_{n+1}, x) \right)}

        Por tanto, el hecho de que la ecuación tenga solución para cualquier valor de $n$ equivale a que $g$ tenga un punto fijo, es decir, que exista $x$ tal que $g(x) = x$. Por el Teorema del punto fijo de Banach, si $g$ es una contracción, entonces tiene un único punto fijo.
        \begin{align*}
            |g(x) - g(y)| &= h(1-\alpha) |f(t_{n+1}, x) - f(t_{n+1}, y)|\leq h(1-\alpha)L |x - y|
        \end{align*}

        Por tanto, $g$ es lipschitziana con constante de Lipschitz $h(1-\alpha)L$. Para que sea una contracción, necesitamos que:
        \begin{equation*}
            h(1-\alpha)L < 1 \implies h < \frac{1}{L(1-\alpha)}\qquad (\alpha\neq 1)
        \end{equation*}

        Por tanto, si $\alpha = 1$, el método es el de Euler y no hay restricción en $h$. Si $\alpha < 1$, la restricción es:
        \begin{equation*}
            h < \frac{1}{L(1-\alpha)}
        \end{equation*}
        \item\label{ap:alpha}
        Determina el valor de $\alpha$ para que el método tenga orden 2. ¿Cuál es en este caso el error de truncatura local? ¿De qué orden es el error global de discretización?

        Para que el método tenga orden 2, necesitamos $C_0=C_1=C_2=0$, mientras que $C_3\neq 0$.
        \begin{align*}
            C_0 &= 1 - 1 = 0\qquad \forall \alpha\in [0, 1] \\
            C_1 &= 1 - \alpha - (1 - \alpha) = 0\qquad \forall \alpha\in [0, 1] \\
            C_2 &= \dfrac{1}{2!} - \frac{1^1}{1!}(1-\alpha) = \frac{1}{2} - 1+ \alpha = 0\iff \alpha = \frac{1}{2} \\
            C_3 &= \dfrac{1}{3!} - \frac{1^2}{2!}(1-\alpha) = \frac{1}{6} - \frac{1}{2} + \frac{\alpha}{2} = \frac{1-3 + 3\alpha}{6} = -\frac{1}{12}\neq 0
        \end{align*}

        Por tanto, el valor de $\alpha$ que buscamos es $\alpha = \nicefrac{1}{2}$. En este caso, el error de truncatura local es:
        \begin{equation*}
            R_{n+1} = -\frac{1}{12}h^3x'''(\xi_n)\qquad \xi_n \in [t_{n-1},t_{n+1}]
        \end{equation*}

        El error global de discretización es de orden $O(h^2)$.

        \item Para el valor obtenido en el apartado anterior, estudia si el método es A-estable. ¿Es el método A-estable para cualquier valor de $\alpha$?
        
        Aplicamos el método a la ecuación $x' = \lm x$, con $\Re(\lm) < 0$.
        \begin{comment}
        \begin{align*}
            x_{n+1} &= x_n + h \left( \alpha \lm x_n + (1 - \alpha) \lm x_{n+1} \right)
            = x_n + \frac{h\lm}{2}(x_n + x_{n+1})
            =\\&= \left(1+ \frac{h\lm}{2}\right)x_n + \frac{h\lm}{2}x_{n+1}
            = \left(\dfrac{1+\frac{h\lm}{2}}{1 - \frac{h\lm}{2}}\right)x_{n}
            = \left(\dfrac{2+h\lm}{2 - h\lm}\right)x_{n}
            = \left(\dfrac{2+h\lm}{2 - h\lm}\right)^nx_{0}
        \end{align*}
        \end{comment}
        \begin{align*}
            x_{n+1} &= x_n + h \left( \alpha \lm x_n + (1 - \alpha) \lm x_{n+1} \right)
            = x_n + h\lm(\alpha x_n + (1-\alpha)x_{n+1})
            =\\&= \left(1+ h\lm\alpha\right)x_n + h\lm(1-\alpha)x_{n+1}
            = \left(\dfrac{1+h\lm\alpha}{1 - h\lm(1-\alpha)}\right)x_{n}
            = \left(\dfrac{1+h\lm\alpha}{1 - h\lm(1-\alpha)}\right)^nx_{0}
        \end{align*}

        Tenemos que el método es A-estable si:
        \begin{equation*}
            \left|\dfrac{1+h\lm\alpha}{1 - h\lm(1-\alpha)}\right| < 1
        \end{equation*}

        Desarrollamos el módulo:
        \begin{align*}
            \left|1+h\lm\alpha\right| &< \left|1 - h\lm(1-\alpha)\right| \\
            &\iff \left|1+h\lm\alpha\right|^2 < \left|(1 +h\lm\alpha) -h\lm\right|^2 \\
            &\iff |1+h\lm\alpha|^2 < |1 +h\lm\alpha|^2 + |h\lm|^2+2\Re\left((1+h\lm\alpha)(\ol{-h\lm})\right) \\
            &\iff 0 < |h\lm|^2-2\Re\left((1+h\lm\alpha)(h\ol{\lm})\right) \\
            &\iff 0 < |h\lm|^2-2\left((1+h\alpha\Re(\lm))h\Re(\lm) + h\Im(\lm)\alpha h\Im(\lm)\right) \\
            &\iff 0 < |h\lm|^2-2\left(h\Re(\lm)+\alpha h^2\Re^2(\lm)+ h^2\Im^2(\lm)\alpha \right) \\
            &\iff 0 < |h\lm|^2-2\left(h\Re(\lm)+\alpha |h\lm|^2\right) \\
            &\iff (2\alpha-1)|h\lm|^2 < -2h\Re(\lm)
        \end{align*}


        Por tanto, como $\Re(\lm) < 0$, distinguimos en función de $\alpha$:
        \begin{itemize}
            \item Si $\alpha \leq \nicefrac{1}{2}$, entonces se da dicha desigualdad. Por tanto:
            \begin{equation*}
                \lim_{n\to\infty} x_n = 0
            \end{equation*}
            En este caso, el método es A-estable.

            \item Si $\alpha > \nicefrac{1}{2}$, entonces la desigualdad no se da. Por tanto, el método no es A-estable.
        \end{itemize}

        \item ¿De qué orden sería un método predictor-corrector en el que el predictor es el método de Euler y el corrector es el correspondiente al apartado~\ref{ap:alpha}?
        
        El corrector hemos visto que es de orden 2. El predictor es el método de Euler, que es de orden 1. Si por tanto utilizamos $m\geq 1$ correcciones, el orden del método predictor-corrector es:
        \begin{equation*}
            \min\{2,1+m\}
        \end{equation*}

        Por tanto, el orden del método predictor-corrector es 2.
        \item Aplica todo lo anterior al problema:
            \begin{equation*}
                \begin{cases}
                    x'(t) = -3x + t \\
                    x(0) = 0.3
                \end{cases}
            \end{equation*}
            para estimar el valor de $x(1)$. Realiza cuatro iteraciones haciendo en cada una una predicción con el método de Euler y una corrección con el método descrito en el apartado~\ref{ap:alpha}. Muestra todas las iteraciones.


            Como buscamos $4$ iteraciones en un intervalo de longitud $1$, tomamos $h = \nicefrac{1}{4}$. Las predicciones serán:
            \begin{align*}
                x_{n+1}^{(0)} &= x_n + h(-3x_n + t_n) = x_n + \frac{1}{4}(-3x_n + t_n)
            \end{align*}

            Las correcciones serán:
            \begin{align*}
                x_{n+1} &= x_n + \frac{h}{2} \left( f(t_n, x_n) + f(t_{n+1}, x_{n+1}^{(0)}) \right)
                =\\&= x_n + \frac{h}{2} \left( -3x_n + t_n + (-3x_{n+1}^{(0)} + t_{n+1}) \right)
            \end{align*}

            Partimos de $x_0=0.3$ y $t_0 = 0$. Por tanto, tenemos:
            \begin{align*}
                x_1^{(0)} &= x_0 + \frac{1}{4}(-3x_0 + t_0) = 0.3 + 0.25(-3\cdot 0.3 + 0) = 0.075 \\
                x_1 &= x_0 + \frac{1}{8} \left( -3x_0 + t_0 + (-3x_1^{(0)} + t_1) \right) =\\&= 0.3 + \frac{1}{8} \left( -3\cdot 0.3 + 0 + (-3\cdot 0.075 + 0.25) \right) = 0.190625
            \end{align*}

            Resumimos los resultados en la siguiente tabla:
            \begin{equation*}
                \begin{array}{c|c|c|c}
                    n & t_n & x_n^{(0)} & x_n \\
                    \hline
                    0 & 0 & & 0.3 \\
                    1 & 0.25 & 0.075 & 0.190625 \\
                    2 & 0.5 & 0.11015625 & 0.17158203 \\
                    3 & 0.75 & 0.16789551 & 0.20052795 \\
                    4 & 1 & 0.23763199 & 0.25496798
                \end{array}
            \end{equation*}
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Dado el problema de valores iniciales
    \begin{equation*}
        \begin{cases}
            x'(t) = f(t, x(t)) \\
            x(a) = \mu
        \end{cases}
    \end{equation*}
    se pretende utilizar el siguiente método numérico para estimar el valor de $x(b)$, con $b > a$:
    \begin{equation*}
        x_{n+2} = x_n + h \left( \beta_0 f(t_n, x_n) + \beta_1 f(t_{n+1}, x_{n+1}) + \beta_2 f(t_{n+2}, x_{n+2}) \right)
    \end{equation*}
    \begin{enumerate}
        \item ¿Podemos asegurar que el método es estable? Estudia su consistencia y su convergencia.
        
        Su polinomio característico es:
        \begin{equation*}
            p(\lm) = \lm^2 - 1 = (\lm - 1)(\lm + 1)
        \end{equation*}

        Por lo tanto, ambas raíces son simples y tienen módulo 1. Por tanto, el método es estable. Respecto a la consistencia, necesitamos que:
        \begin{itemize}
            \item $p(1) = 0$, que se tiene.
            \item $\Phi(x(t_n), x(t_n), t_n, 0) = p'(1)f(t_n, x(t_n))$:
            \begin{align*}
                \Phi(x(t_n), x(t_n), t_n, 0) &= \beta_0 f(t_n, x(t_n)) + \beta_1 f(t_n, x(t_n)) + \beta_2 f(t_n, x(t_n))
                =\\&= (\beta_0 + \beta_1 + \beta_2)f(t_n, x(t_n)) = p'(1)f(t_n, x(t_n))
                =\\&= 2f(t_n, x(t_n))
                \iff  \beta_0 + \beta_1 + \beta_2 = 2
            \end{align*}
        \end{itemize}
        Por lo tanto, el método es consistente si y solo si $\beta_0 + \beta_1 + \beta_2 = 2$. Por tanto, tenemos que el método es convergente si y solo si:
        \begin{equation*}
            \beta_0 + \beta_1 + \beta_2 = 2
        \end{equation*}
        \item Determina el valor de los parámetros para que el método tenga orden al menos 3. ¿Es algún método conocido? ¿Cuál es en este caso el error de truncatura local? ¿De qué orden es el error global de discretización?
        
        Para que el método tenga orden al menos 3, necesitamos $C_0=C_1=C_2=C_3=0$.
        \begin{align*}
            C_0 &= 1 - 1 = 0\qquad \forall \beta_0, \beta_1, \beta_2 \\
            C_1 &= 2 - \beta_0 - \beta_1 - \beta_2 = 0\\
            C_2 &= \dfrac{2^2}{2!} - \frac{1^1}{1!}\beta_1 - \frac{2^1}{1!}\beta_2 = 2 - \beta_1 - 2\beta_2 = 0\\
            C_3 &= \dfrac{2^3}{3!} - \frac{1^2}{2!}\beta_1 - \frac{2^2}{2!}\beta_2 = \frac{4}{3} - \frac{\beta_1}{2} - 2\beta_2 = 0
        \end{align*}

        Planteamos el sistema de ecuaciones:
        \begin{equation*}
            \left.\begin{array}{rcl}
                \beta_0 + \beta_1 + \beta_2 & = & 2 \\
                -\beta_1 - 2\beta_2 & = & -2 \\
                \nicefrac{\beta_1}{2} + 2\beta_2 & = & \nicefrac{4}{3}
            \end{array}\right\}
            \Longrightarrow
            \left\{\begin{array}{rcl}
                \beta_0 & = & \nicefrac{1}{3} \\
                \beta_1 & = & \nicefrac{4}{3} \\
                \beta_2 & = & \nicefrac{1}{3}
            \end{array}\right.
        \end{equation*}

        Por tanto, el método resultante es:
        \begin{align*}
            x_{n+2} &= x_n + h \left( \frac{1}{3} f(t_n, x_n) + \frac{4}{3} f(t_{n+1}, x_{n+1}) + \frac{1}{3} f(t_{n+2}, x_{n+2}) \right)
            =\\&= x_n + \frac{h}{3} \left( f(t_n, x_n) + 4f(t_{n+1}, x_{n+1}) + f(t_{n+2}, x_{n+2}) \right)
        \end{align*}

        Como vemos, se trata del método obtenido a partir de la fórmula simple de Simpson aplicada al intervalo $[t_n, t_{n+2}]$. Para calcular el error de truncatura local, calculamos previamente el orden del método:
        \begin{align*}
            C_4 &= \dfrac{2^4}{4!} - \frac{1^3}{3!}\beta_1 - \frac{2^3}{3!}\beta_2 = \frac{2}{3} - \frac{\beta_1}{6} - \frac{4\beta_2}{2} = 0\\
            C_5 &= \dfrac{2^5}{5!} - \frac{1^4}{4!}\beta_1 - \frac{2^4}{4!}\beta_2 = -\frac{1}{90}\neq 0
        \end{align*}

        Por tanto, el orden del método es 4 y el error de truncatura local es:
        \begin{equation*}
            R_{n+2} = -\frac{1}{90}h^5x^{(5)}(\xi_n) \qquad \xi_n \in [t_{n-1},t_{n+1}]
        \end{equation*}
        
        El error global de discretización es de orden $O(h^4)$.
        \item ¿De qué orden sería un método predictor-corrector en el que el predictor es el método de Runge-Kutta óptimo de dos evaluaciones y el corrector es el correspondiente al apartado anterior?
        
        El corrector hemos visto que es de orden 4. El predictor es el método de Runge-Kutta óptimo de dos evaluaciones, que es de orden 2. Si por tanto utilizamos $m\geq 1$ correcciones, el orden del método predictor-corrector es:
        \begin{equation*}
            \min\{4,2+m\}
        \end{equation*}

        Lo ideal será por tanto emplear $m=2$ correcciones, de modo que el orden del método predictor-corrector sea 4.
        \item Aplica todo lo anterior al problema:
            \begin{equation*}
                \begin{cases}
                    x'(t) = -3x + t \\
                    x(0) = 0.3
                \end{cases}
            \end{equation*}
            para estimar el valor de $x(1)$. Realiza cuatro iteraciones haciendo en cada una predicción con el método de Runge-Kutta óptimo de dos evaluaciones y una corrección con el método descrito en el apartado anterior. Si necesitas algún valor inicial para empezar el método predictor-corrector, utiliza también Runge-Kutta óptimo de dos evaluaciones para estimarlo. Muestra los resultados de todas las iteraciones que realices.

            Como buscamos $4$ iteraciones en un intervalo de longitud $1$, tomamos $h = \nicefrac{1}{4}$. El método predictor es el Runge-Kutta óptimo de dos evaluaciones:
            \begin{align*}
                x_{n+1}^{(0)} &= x_n + \frac{h}{4} \left( f(t_n, x_n) + 3f\left(t_n + \frac{2h}{3}, x_n + \frac{2h}{3}f(t_n, x_n)\right) \right)
                =\\&= x_n + \frac{h}{4} \left( -3x_n + t_n + 3\left(-3\left(x_n + \frac{2h}{3}\left(-3x_n + t_n\right)\right) + \left(t_n + \frac{2h}{3}\right)\right) \right)
                =\\&= x_n + \frac{h}{4} \left( -3x_n + t_n -9\left(x_n + \frac{2h}{3}\left(-3x_n + t_n\right)\right) + 3\left(t_n + \frac{2h}{3}\right) \right)
                =\\&= x_n + \frac{h}{4} \left( -12x_n + 4t_n -6h\left(-3x_n + t_n\right) + 2h \right)
            \end{align*}

            El método corrector es el que hemos visto en el apartado anterior:
            \begin{align*}
                x_{n+2} &= x_n + \frac{h}{3} \left( f(t_n, x_n) + 4f(t_{n+1}, x_{n+1}) + f(t_{n+2}, x_{n+2}^{(0)}) \right)
                =\\&= x_n + \frac{h}{3} \left( -3x_n + t_n + 4\left(-3x_{n+1} + t_{n+1}\right) + \left(-3x_{n+2}^{(0)} + t_{n+2}\right) \right)
            \end{align*}

            Vemos que este requiere de dos semillas. La segunda la obtenemos con el método de Runge-Kutta óptimo de dos evaluaciones:
            \begin{align*}
                x_1 = x_1^{(0)} = 0.190625
            \end{align*}

            Realizamos ahora $4$ iteraciones del método predictor-corrector, reflejadas en la siguiente tabla:
            \begin{equation*}
                \begin{array}{c|c|c|c}
                    n & t_n & x_n^{(0)} & x_n \\
                    \hline
                    0 & 0 & & 0.3\\
                    1 & 0.25 & 0.190625 & 0.190625 \\
                    2 & 0.5 & 0.17158203 & 0.11647949 \\
                    3 & 0.75 & 0.17125473 & 0.23367558 \\
                    4 & 1 & 0.27257765 & 0.16053963
                \end{array}
            \end{equation*}


    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Dado el problema de valores iniciales
    \begin{equation*}
        \begin{cases}
            x'(t) = f(t, x(t)) \\
            x(a) = \mu
        \end{cases}
    \end{equation*}
    se pretende utilizar el siguiente método numérico para estimar el valor de $x(b)$, con $b > a$:
    \begin{equation*}
        x_{n+2} = \alpha_1 x_{n+1} + \alpha_0 x_n + h \left( \beta_1 f(t_{n+1}, x_{n+1}) + \beta_0 f(t_n, x_n) \right)
    \end{equation*}
    \begin{enumerate}
        \item Determina el valor de los parámetros (en función del parámetro $\alpha_1$) para que el método tenga orden al menos 2. ¿Sería consistente en ese caso?
        
        Para que el método tenga orden al menos 2, necesitamos $C_0=C_1=0$.
        \begin{align*}
            C_0 &= 1 - \alpha_1 - \alpha_0 = 0 \\
            C_1 &= 2 - \alpha_1 - \beta_1 - \beta_0\\
            C_2 &= \dfrac{2^2}{2!} - \frac{1^2}{2!}\alpha_1 - \frac{1^1}{1!}\beta_1 = 2 - \frac{\alpha_1}{2} - \beta_1 = 0
        \end{align*}

        Por tanto, la solución uniparamétrica del sistema es:
        \begin{equation*}
            \left\{\begin{array}{rcl}
                \alpha_0 & = & 1 - \alpha_1 \\
                \beta_0 & = & 2 - \alpha_1 - \beta_1 = -\frac{\alpha_1}{2} \\
                \beta_1 & = & 2 - \frac{\alpha_1}{2}
            \end{array}\right.
        \end{equation*}

        Por tanto, el método resultante es:
        \begin{align*}
            x_{n+2} &= \alpha_1 x_{n+1} + (1 - \alpha_1) x_n + h \left( \left(2 - \frac{\alpha_1}{2}\right) f(t_{n+1}, x_{n+1}) - \frac{\alpha_1}{2} f(t_n, x_n) \right)
        \end{align*}

        Este método es consistente, puesto que $C_0=C_1=0$.
        \item Estima el error de truncatura local (también en función de $\alpha_1$). ¿De qué orden es el error global de discretización?
        
        Para calcular el error de truncatura local, calculamos previamente el orden del método:
        \begin{align*}
            C_3 &= \dfrac{2^3}{3!} - \frac{1^3}{3!}\alpha_1 - \frac{1^2}{2!}\beta_1 = \frac{4}{3} - \frac{\alpha_1}{6} - \frac{2 - \frac{\alpha_1}{2}}{2} = \frac{4}{3} - \frac{\alpha_1}{6} - 1 + \frac{\alpha_1}{4}
            = \frac{1}{3} + \frac{\alpha_1}{12}
        \end{align*}
        Por tanto, el orden del método es 3 y el error de truncatura local es:
        \begin{equation*}
            R_{n+2} = \left(\frac{1}{3} + \frac{\alpha_1}{12}\right)h^3x^{(3)}(\xi_n) \qquad \xi_n \in [t_{n-1},t_{n+1}]
        \end{equation*}

        El error global de discretización es de orden $O(h^2)$, puesto que el orden del método es 2.
        \item Estudia la estabilidad y la convergencia en función del parámetro $\alpha_1$.
        
        Respecto a la consistencia, hemos de imponer que $C_0=C_1=0$, lo cual ya hemos hecho en el apartado anterior. Por tanto, el método es consistente.
        Respecto a la estabilidad, obtenemos el polinomio característico:
        \begin{align*}
            p(\lm) &= \lm^2 - \alpha_1\lm - \alpha_0
            = \lm^2 - \alpha_1\lm - (1 - \alpha_1) = (\lm - 1)(\lm + 1-\alpha_1)
        \end{align*}

        Por tanto, las raíces son $\lm_1 = 1$ y $\lm_2 = \alpha_1 - 1$. Tenemos por tanto que es estable si y solo si $\alpha\in \ol{D}(1,1)\setminus \{2\}$. Por tanto, es método es convergente si y solo si $\alpha_1 \in \ol{D}(1,1)\setminus \{2\}$ y, además, $C_0=C_1=0$.

        \item Si $\alpha_1 = 0$, ¿encuentras relación con algún método conocido? ¿Y en el caso $\alpha_1 = 1$?
        
        Para $\alpha_1 = 0$, tenemos:
        \begin{align*}
            x_{n+2} &= x_n + h \left( 2 f(t_{n+1}, x_{n+1})\right)
        \end{align*}
        Este es el método del punto medio, que surge de aplicar la fórmula de cuadratura del punto medio al intervalo $[t_n, t_{n+2}]$.

        Para $\alpha_1 = 1$, tenemos:
        \begin{align*}
            x_{n+2} &= x_{n+1} + h \left(\dfrac{3}{2} f(t_{n+1}, x_{n+1}) - \frac{1}{2} f(t_n, x_n)\right)
        \end{align*}
        \item Utiliza este método con $\alpha_1 = \nicefrac{1}{2}$ en el problema de valores iniciales
            \begin{equation*}
                \begin{cases}
                    x'(t) = -3x + t \\
                    x(0) = 0.3
                \end{cases}
            \end{equation*}
            para estimar el valor de $x(1)$. Realiza cuatro iteraciones del método haciendo uso del método de Euler para calcular los datos iniciales que necesites. Muestra todas las iteraciones.



            Como buscamos $4$ iteraciones en un intervalo de longitud $1$, tomamos $h = \nicefrac{1}{4}$. Este método necesita de dos semillas:
            \begin{align*}
                x_0 = x(0) &= 0.3 \\
                x_1 &= x_0 + h(-3x_0+0) = 0.3 + \frac{1}{4}(-3\cdot 0.3 + 0) = \frac{3}{40} = 0.075
            \end{align*}

            El método con $\alpha_1 = \nicefrac{1}{2}$ y aplicado a este problema es:
            \begin{align*}
                x_{n+2} &= \frac{1}{2} x_{n+1} + \frac{1}{2} x_n + h \left( \frac{3}{4} f(t_{n+1}, x_{n+1}) - \frac{1}{4} f(t_n, x_n) \right)
                =\\&= \frac{1}{2}\left(x_{n+1} + x_n\right) + \frac{h}{4} \left(3f(t_{n+1}, x_{n+1}) - f(t_n, x_n)\right)
                =\\&= \frac{1}{2}\left(x_{n+1} + x_n\right) + \frac{h}{4} \left(3(-3x_{n+1}+t_{n+1}) - (-3x_n+t_n)\right)
            \end{align*}

            Realizamos las iteraciones:
            \begin{equation*}
                \begin{array}{c|c|c}
                    n & t_n & x_n \\
                    \hline
                    0 & 0 & 0.3 \\
                    1 & 0.25 & 0.075 \\
                    2 & 0.5 & 0.2484375 \\
                    3 & 0.75 & 0.11416016 \\
                    4 & 1 & 0.27304077
                \end{array}
            \end{equation*}
    \end{enumerate}
\end{ejercicio}~\\

\begin{ejercicio}~
    \begin{enumerate}
        \item Para el PVI $x' = x - |t - 2|$, $x(0) = 1$, $t \in [0, 1]$ con $h = 0.1$, calcula $x_1$ con el MML asociado al arreglo de Butcher
            \begin{equation*}
                \begin{array}{c|ccc}
                    1 & 1 & 0 & 0 \\
                    1 & 1 & 0 & 0 \\
                    1 & 0 & 1 & 0 \\ \hline
                    & \nicefrac{1}{2} & \nicefrac{1}{6} & \nicefrac{1}{3}
                \end{array}
            \end{equation*}

            El método de Runge-Kutta asociado a este arreglo de Butcher es:
            \begin{align*}
                x_{n+1} &= x_n + h \left( \frac{1}{2} K_1 + \frac{1}{6} K_2 + \frac{1}{3} K_3 \right) \\
                K_1 &= f(t_n + h, x_n + h K_1) = x_n + h K_1 - |t_n + h - 2| \\
                K_2 &= f(t_n + h, x_n + h K_1) = x_n + h K_1 - |t_n + h - 2| \\
                K_3 &= f(t_n + h, x_n) = x_n - |t_n - 2|
            \end{align*}

            Calculamos por tanto $x_1$, sabiendo que $t_0 = 0$, $x_0 = 1$ y $h = 0.1$:
            \begin{align*}
                K_1 &= 1 + 0.1 K_1 - |0.1 - 2| = 1 + 0.1 K_1 - 1.9 
                \Longrightarrow K_1 = \frac{-0.9}{0.9} = -1 \\
                K_2 &= 1 + 0.1(-1) - |0.1 - 2| = 1 - 0.1 - 1.9 = -1 \\
                K_3 &= 1 - |0 - 2| = 1 - 2 = -1\\
                x_1 &= 1 + 0.1 \left( \frac{1}{2}(-1) + \frac{1}{6}(-1) + \frac{1}{3}(-1) \right) = \frac{9}{10}
            \end{align*}
        \item Estudia las propiedades (estabilidad, consistencia, convergencia, orden, parte principal del error de truncatura local) del método
        \begin{equation*}
            x_{n+1} = \frac{2}{3} x_n + \frac{1}{3} x_{n-1} + \frac{h}{3} (5 f_n - f_{n-1}).
        \end{equation*}

        En primer lugar, hemos de cambiar la notación:
        \begin{equation*}
            x_{n+2} = \frac{2}{3} x_{n+1} + \frac{1}{3} x_n + \frac{h}{3} (5 f_{n+1} - f_n).
        \end{equation*}

        El polinomio característico del método es:
        \begin{equation*}
            p(\lm) = \lm^2 - \frac{2}{3}\lm - \frac{1}{3} = 0\iff \lm \in \left\{1,-\frac{1}{3}\right\}
        \end{equation*}

        Por tanto, el método es estable, puesto que ambas raíces están en el disco unidad, y la de módulo 1 es simple.
        Respecto a la consistencia, hemos de ver que $C_0=C_1=0$:
        \begin{align*}
            C_0 &= 1 - \frac{2}{3} - \frac{1}{3} = 0 \\
            C_1 &= 2 - \frac{2}{3} - \frac{5}{3} + \frac{1}{3} = 0
        \end{align*}
        Por tanto, el método es consistente. Como es consistente y estable, es convergente. Para ver el orden del método, calculamos los $C_i$:
        \begin{align*}
            C_2 &= \dfrac{2^2}{2!} - \frac{1^2}{2!}\cdot\frac{2}{3} - \frac{1^1}{1!}\cdot\frac{5}{3} = 2 - \frac{1}{3} - \frac{5}{3} = 0\\
            C_3 &= \dfrac{2^3}{3!} - \frac{1^3}{3!}\cdot\frac{2}{3} - \frac{1^2}{2!}\cdot\frac{5}{3} = \frac{7}{18}\neq 0
        \end{align*}

        Por tanto, el orden del método es 2 y el término principal del error de truncatura local es:
        \begin{equation*}
            \frac{7}{18}h^3x^{(3)}(t_n)
        \end{equation*}

    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Utiliza la fórmula de cuadratura del trapecio para deducir la fórmula del trapecio para resolución de PVI así como el error de truncatura local. Estudia también la A-estabilidad del método.

    \begin{align*}
        x_{n+1} - x_n &\approx x(t_{n+1}) - x(t_n) = \int_{t_n}^{t_{n+1}} x'(t)dt = \int_{t_n}^{t_{n+1}} f(t, x(t))dt
        \approx \\& \approx \frac{h}{2} \left( f(t_n, x(t_n)) + f(t_{n+1}, x(t_{n+1})) \right)
        \approx \frac{h}{2} \left( f_n + f_{n+1} \right)
    \end{align*}

    Por tanto, el método del trapecio es:
    \begin{equation*}
        x_{n+1} = x_n + \frac{h}{2} \left( f_n + f_{n+1} \right)
    \end{equation*}

    Calculamos ahora el error de truncatura local:
    \begin{align*}
        C_0 &= 1 - 1 = 0 \\
        C_1 &= 1 - \frac{1}{2} - \frac{1}{2} = 1 \neq 0 \\
        C_2 &= \frac{1}{2!} - \frac{1^1}{1!}\cdot \frac{1}{2} = 0\\
        C_3 &= \frac{1}{3!} - \frac{1^2}{2!}\cdot \frac{1}{2} = \frac{1}{6} - \frac{1}{4} = -\frac{1}{12}\neq 0
    \end{align*}

    Por tanto, el orden del método es 2 y el error de truncatura local es:
    \begin{equation*}
        R_{n+1} = -\frac{1}{12}h^3x^{(3)}(\xi_n) \qquad \xi_n \in [t_n, t_{n+1}]
    \end{equation*}

    Respecto a la A-estabilidad, consideramos el PVI $x'=\lm x$, $x(0) = \mu$, con $\Re(\lm) < 0$. En este caso, el método del trapecio es:
    \begin{align*}
        x_{n+1} &= x_n + \frac{h}{2} \left( \lm x_n + \lm x_{n+1} \right) = x_n + \frac{\lm h}{2} (x_n + x_{n+1})
        = \left(1+ \frac{\lm h}{2}\right)x_n + \frac{\lm h}{2} x_{n+1}
        =\\&= \left(\dfrac{1+ \frac{\lm h}{2}}{1 - \frac{\lm h}{2}}\right)x_n
        = \left(\dfrac{2+ \lm h}{2 - \lm h}^n\right)x_0
    \end{align*}

    Sea ahora $w=\lm h\in \bb{C}$, y calculemos la región de $A-$estabilidad del método:
    \begin{align*}
        \left|\dfrac{2+w}{2-w}\right| &< 1 \iff \left|2+w\right| < \left|2-w\right| \\
        \iff \left|2+w\right|^2 &< \left|2-w\right|^2
        \iff 2^2 + |w|^2 + 2\Re(w) < 2^2 + |w|^2 - 2\Re(w) \\
        \iff \Re(w) &< 0
    \end{align*}

    Como la región de $A-$estabilidad contiene al semiplano izquierdo, el método del trapecio es $A-$estable.
\end{ejercicio}

\begin{ejercicio}
    Dado el método multipaso lineal
    \begin{equation*}
        x_{n+2} = \frac{2a + 1}{2} x_{n+1} - \frac{a}{2} x_n + h \left( \beta_0 f(t_n, x_n) + \beta_2 f(t_{n+2}, x_{n+2}) \right)
    \end{equation*}
    \begin{enumerate}
        \item Estudia la convergencia del método.
        
        Estudiemos en primer lugar la consistencia del método, para lo cual hemos de imponer que $C_0=C_1=0$:
        \begin{align*}
            C_0 &= 1 - \frac{2a + 1}{2} + \frac{a}{2} = 0 \iff 2 = a+1\iff a = 1
        \end{align*}

        Por tanto, suponeos $a=1$. Impongamos ahora que $C_1=0$:
        \begin{align*}
            C_1 &= 2 - \frac{3}{2} - \beta_0 - \beta_2 = 0 \iff \beta_0 + \beta_2 = \frac{1}{2}
        \end{align*}

        Por tanto, el método es consistente si y solo si $a=1$ y $\beta_0 + \beta_2 = \frac{1}{2}$.

        Respecto a la estabilidad, el polinomio característico del método es:
        \begin{align*}
            p(\lm) &= \lm^2 - \frac{2a + 1}{2}\lm + \frac{a}{2} = 0\iff
            2\lm^2 -2a\lm + a-1 = 0
            \iff \\ &\iff
            \lm = \frac{2a \pm \sqrt{(2a)^2 - 8(a-1)}}{4} = \frac{2a \pm \sqrt{4a^2 - 8a + 8}}{4} = \frac{a \pm \sqrt{a^2 - 2a + 2}}{2}
        \end{align*}

        El radicando es siempre positivo, por lo que siempre hay dos raíces reales distintas. Para que el método sea estable, hemos de imponer que ambas raíces estén en el disco unidad.
        \begin{align*}
            \left|\frac{a \pm \sqrt{a^2 - 2a + 2}}{2}\right| \leq 1 & \iff \left|a \pm \sqrt{a^2 - 2a + 2}\right| \leq 2
            \\ &\iff -2 \leq a \pm \sqrt{a^2 - 2a + 2} \leq 2
            \\ &\iff -2-a \leq \pm \sqrt{a^2 - 2a + 2} \leq 2-a
        \end{align*}

        Por tanto, el método es estable si y solo si:
        \begin{align*}
            -2-a \leq \pm \sqrt{a^2 - 2a + 2} \leq 2-a
        \end{align*}

        Como tan solo nos piden estudiar la convergencia del método, no vamos a resolver estas desigualdades, puesto que sabemos que si $a\neq 1$ el método no es consistente y, por tanto, no es convergente. Si $a=1$, hemos de estudiar las desigualdades anteriores para ver si el método es estable.
        \begin{equation*}
            -3 \leq \pm 1 \leq 1
        \end{equation*}

        Por tanto, en ese caso, el método es estable también. Por tanto, el método es convergente si y solo si $a=1$ y $\beta_0 + \beta_2 = \frac{1}{2}$.

        \item Determina el valor de los parámetros para que el método sea convergente y tenga el mayor orden posible. ¿Cuál es ese orden? Indica el término principal del error de truncatura local en este caso.
        
        Imponemos que $C_i$ se anulen para $i=0,1,2$:
        \begin{align*}
            C_0 &= 0 \iff a=1 \\
            C_1 &= 0 \iff \beta_0 + \beta_2 = \frac{1}{2} \\
            C_2 &= \frac{2^2}{2!} - \frac{1^2}{2!}\cdot\frac{3}{2} - \frac{2^1}{1!}\cdot\beta_2 = 0 \iff \beta_2 = \frac{5}{8}\Longrightarrow
            \beta_0 = \frac{1}{2} - \frac{5}{8} = -\frac{1}{8}\\
            C_3 &= \frac{2^3}{3!} - \frac{1^3}{3!}\cdot\frac{3}{2} - \frac{2^2}{2!}\cdot\frac{5}{8} = \frac{4}{3} - \frac{1}{4} - \frac{10}{8} = -\frac{1}{6}\neq 0
        \end{align*}

        Por tanto, en este caso el método resultante es:
        \begin{equation*}
            x_{n+2} = \frac{3}{2} x_{n+1} - \frac{1}{2} x_n + \frac{h}{8}\left( -f(t_n, x_n) + 5 f(t_{n+2}, x_{n+2}) \right)
        \end{equation*}

        En este caso, el orden del método es 2 y el término principal del error de truncatura local es:
        \begin{equation*}
            -\frac{1}{6}h^3x^{(3)}(t_n)
        \end{equation*}
        \item Para el PVI
            \begin{equation*}
                \begin{cases}
                    x'(t) = -3x + t^2 \\
                    x(0) = 1
                \end{cases}
            \end{equation*}
            toma $h = 0.1$ y utiliza el método de Euler para aproximar $x(0.1)$. Realiza a continuación dos iteraciones del método que has obtenido en el apartado anterior para aproximar $x(0.3)$.

            Utilizando el método de Euler, tenemos:
            \begin{align*}
                x_0 &= 1 \\
                x_1 &= x_0 + h(-3x_0 + t_0^2) = 1 + 0.1(-3\cdot 1 + 0^2) = 1 - 0.3 = 0.7
            \end{align*}

            El método del apartado anterior, en este caso, queda:
            \begin{align*}
                x_{n+2} &= \frac{3}{2} x_{n+1} - \frac{1}{2} x_n + \frac{h}{8}\left( 3x_n - t_n^2 -15 x_{n+2} + 5 t_{n+2}^2 \right)
            \end{align*}
            Realizamos ahora dos iteraciones del método, partiendo de $x_1=0.7$:
            \begin{align*}
                x_2 &= \frac{3}{2} x_1 - \frac{1}{2} x_0 + \frac{0.1}{8}\left( 3x_0 - t_0^2 -15 x_2 + 5 t_2^2 \right) \\
                &= \frac{11}{20} + 0.0125\left( 3 - 15x_2 + 0.2 \right) \\
                &= 0.59 - 0.1875 x_2 = \frac{0.59}{1 + 0.1875} \approx 0.4968421\\
                x_3 &= \frac{3}{2} x_2 - \frac{1}{2} x_1 + \frac{0.1}{8}\left( 3x_1 - t_1^2 -15 x_3 + 5 t_3^2 \right) \\
                &= \frac{751}{1900} + 0.0125\left( 2.09 - 15x_3 + 0.45 \right) \\
                &= 0.0125496 - 0.1875 x_3 = \frac{0.0125496}{1 + 0.1875} \approx 0.010568
            \end{align*}
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}\label{ej:3.2.7}
    Para aproximar la solución del PVI
    \begin{equation*}
        \begin{cases}
            x' = f(t, x) \\
            x(t_0) = \mu
        \end{cases}
    \end{equation*}
    se considera el método multipaso
    \begin{equation*}
        x_{n+3} = x_n + h \left( \beta_1 f(t_{n+1}, x_{n+1}) + \beta_2 f(t_{n+2}, x_{n+2}) \right)
    \end{equation*}
    \begin{enumerate}
        \item\label{ej:3.2.7.1}
        ¿Qué relaciones deben existir entre los parámetros $\beta_1$ y $\beta_2$ para que el método anterior sea convergente?\\
        
        Como se trata de un MML, para estudiar la consistencia hemos de imponer que $C_0=C_1=0$:
        \begin{align*}
            C_0 &= 1 - 1 = 0 \\
            C_1 &= 3 - \beta_1 - \beta_2 = 0 \iff \beta_1 + \beta_2 = 3
        \end{align*}

        Para estudiar la estabilidad, hemos de calcular el polinomio característico del método:
        \begin{align*}
            p(\lm) &= \lm^3 - 1 = 0\iff \lm^3=1
        \end{align*}

        Sabemos que esa ecuación tiene tres raíces complejas distintas de módulo 1, por lo que el método es estable. Por tanto, el método es convergente si y solo si $\beta_1 + \beta_2 = 3$.


        \item \label{ej:3.2.7.2}Calcula los coeficientes $\beta_1$ y $\beta_2$ para que el método sea convergente y tenga orden máximo. Indica el error de convergencia local en este caso.
        
        Imponemos que $C_i=0$ para $i=0,1,2$:
        \begin{align*}
            C_0 &= 1 - 1 = 0 \\
            C_1 &= 3 - \beta_1 - \beta_2 = 0 \iff \beta_1 + \beta_2 = 3 \\
            C_2 &= \frac{3^2}{2!} - \frac{1^1}{1!}\cdot\beta_1 - \frac{2^1}{1!}\cdot\beta_2 = \frac{9}{2} - \beta_1 - 2\beta_2 = 0
        \end{align*}

        Resolvemos por tanto el sistema:
        \begin{equation*}
            \left\{
                \begin{array}{lcl}
                    \beta_1 + \beta_2 & = & 3 \\
                    -\beta_1 - 2\beta_2 & = & -\frac{9}{2}
                \end{array}
            \right\}
            \Longrightarrow
            \left\{
                \begin{array}{lcl}
                    \beta_1 & = & \nicefrac{7}{2} \\
                    \beta_2 & = & \nicefrac{-1}{2}
                \end{array}
            \right.
        \end{equation*}

        Por tanto, el método resultante es:
        \begin{equation*}
            x_{n+3} = x_n + \frac{h}{2}\left(7 f(t_{n+1}, x_{n+1}) - f(t_{n+2}, x_{n+2})\right)
        \end{equation*}

        Calculemos $C_3$:
        \begin{align*}
            C_3 &= \frac{3^3}{3!} - \frac{1^2}{2!}\cdot\beta_1 - \frac{2^2}{2!}\cdot\beta_2 = \frac{9}{2} - \frac{7}{4} +1 = \frac{15}{4}\neq 0
        \end{align*}

        Por tanto, el orden del método es 2 y el error de truncatura local es:
        \begin{equation*}
            R_{n+3} = \frac{15}{4}h^3x^{(3)}(\xi_n) \qquad \xi_n \in [t_n, t_{n+3}]
        \end{equation*}


        \item Dado el PVI:
            \begin{equation*}
                \begin{cases}
                    x' = -5x + t^2 \\
                    x(0) = 1
                \end{cases}
            \end{equation*}
            realiza dos iteraciones del método de Euler y a continuación, usando esos valores como semilla, realiza otras dos iteraciones del método propuesto con $h = 0.1$.

            En este caso, el método de Euler es:
            \begin{align*}
                x_{n+1} &= x_n + 0.1(-5x_n + t_n^2)
            \end{align*}

            El método propuesto es:
            \begin{align*}
                x_{n+3} &= x_n + \frac{h}{2}\left(7 f(t_{n+1}, x_{n+1}) - f(t_{n+2}, x_{n+2})\right) \\
                &= x_n + 0.05\left(-35x_{n+1} + 7t_{n+1}^2 +5x_{n+2} - t_{n+2}^2\right)
            \end{align*}

            Las aproximaciones realizadas son:
            \begin{equation*}
                \begin{array}{c|c|c}
                    n & t_n & x_n \\
                    \hline
                    0 & 0 & 1\\
                    1 & 0.1 & 0.5 \\
                    2 & 0.2 & 0.251 \\
                    3 & 0.3 & 0.18925 \\
                    4 & 0.4 & 0.1175625
                \end{array}
            \end{equation*}
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Dado el PVI
    \begin{equation*}
        \begin{cases}
            x' = f(t, x) \\
            x(t_0) = \mu
        \end{cases}
    \end{equation*}
    utiliza la fórmula
    \begin{equation*}
        \int_a^{a+h} f(x)dx = \frac{5h}{12} f(a + h) + \frac{2h}{3} f(a) - \frac{h}{12} f(a - h) + R(f)
    \end{equation*}
    para construir razonadamente un método lineal multipaso de la forma
    \begin{equation*}
        x_{n+2} = x_{n+1} + h(\beta_2 f_{n+2} + \beta_1 f_{n+1} + \beta_0 f_n)
    \end{equation*}
    y contesta a las siguientes preguntas:
    \begin{enumerate}
        \item ¿Es el método convergente?
        
        En primer lugar, construimos el método:
        \begin{align*}
            x_{n+2} - x_{n+1} &\approx x(t_{n+2}) - x(t_{n+1}) = \int_{t_{n+1}}^{t_{n+2}} f(t, x(t))dt = \int_{t_{n+1}}^{t_{n+2}} f(t, x(t))dt
            \approx \\& \approx \frac{5h}{12} f(t_{n+2}, x(t_{n+2})) + \frac{2h}{3} f(t_{n+1}, x(t_{n+1})) - \frac{h}{12} f(t_n, x(t_n))
            \approx \\&\approx \frac{5h}{12} f_{n+2} + \frac{2h}{3} f_{n+1} - \frac{h}{12} f_n
        \end{align*}

        Por tanto, tenemos que:
        \begin{equation*}
            \beta_2 = \frac{5}{12}, \quad \beta_1 = \frac{2}{3}, \quad \beta_0 = -\frac{1}{12}
        \end{equation*}

        Para ver si el método es convergente, hemos de estudiar en primer lugar si es consistente, para lo cual hemos de imponer que $C_0=C_1=0$:
        \begin{align*}
            C_0 &= 1 - 1 = 0\\
            C_1 &= 2 - 1 - \frac{2}{3} - \frac{5}{12} + \frac{1}{12} = 0
        \end{align*}

        Por tanto, sí es consistente. Ahora hemos de estudiar la estabilidad del método, para lo cual calculamos el polinomio característico:
        \begin{align*}
            p(\lm) &= \lm^2 - \lm = \lm(\lm - 1) = 0\iff \lm = 0, 1
        \end{align*}
        Por tanto, el método es estable, puesto que una de las raíces es 0 y la otra es 1, ambas en el disco unidad. Como es consistente y estable, el método es convergente.
        \item ¿Cuál es el orden de convergencia local del método?
        
        Para calcular el orden del método, hemos de calcular los $C_i$:
        \begin{align*}
            C_2 &= \frac{2^2}{2!} - \frac{1^2}{2!}\cdot 1 -\frac{1^1}{1!}\beta_1 - \frac{2^1}{1!}\beta_2 = 0\\
            C_3 &= \frac{2^3}{3!} - \frac{1^3}{3!}\cdot 1 - \frac{1^2}{2!}\cdot\beta_1 - \frac{2^2}{2!}\cdot\beta_2 = -\frac{1}{6}\neq 0
        \end{align*}

        Por tanto, el orden del método es 2.
        \item Si queremos utilizar el método de Euler como predictor y este método como corrector para resolver el problema, ¿cuál es el número óptimo de correcciones que se deberían aplicar?
        
        El método de Euler es un método de orden 1, y este método es de orden 2. Por tanto, si $m\geq 1$ es el número de correcciones, el orden del método predictor-corrector será:
        \begin{equation*}
            \min\{2,1+m\} = 2
        \end{equation*}

        Por tanto, el número óptimo de correcciones es $m=1$.
        \item Se pretende aproximar $x(1)$ donde $x(t)$ es la solución del PVI
            \begin{equation*}
                \begin{cases}
                    x' = 3x - 2 \\
                    x(0) = 1
                \end{cases}
            \end{equation*}
            Para ello, tomando $h = \nicefrac{1}{3}$, utiliza el método de Euler para la primera iteración. A continuación utiliza un método predictor-corrector donde el predictor es el método de Euler y el corrector es el método anterior con una única corrección en cada paso.


        El método de Euler es:
        \begin{align*}
            x_{n+1}^{(0)} &= x_n + h(3x_n - 2)
        \end{align*}

        El método corrector es:
        \begin{align*}
            x_{n+2} &= x_{n+1} + h\left(\frac{5}{12}\left(3x_{n+2}^{(0)} - 2\right) + \frac{2}{3}\left(3x_{n+1} - 2\right) - \frac{1}{12}\left(3x_n - 2\right)\right)
        \end{align*}

        Las aproximaciones son:
        \begin{equation*}
            \begin{array}{c|c|c|c}
                n & t_n & x_n^{(0)} & x_n \\
                \hline
                0 & 0 &  & 1\\
                1 & \nicefrac{1}{3} & \nicefrac{4}{3} & \nicefrac{4}{3} \\
                2 & \nicefrac{2}{3} & 2 & 2.3055555 \\
                3 & 1 & 3.94444444 & 4.70833333
            \end{array}
        \end{equation*}
    \end{enumerate}
\end{ejercicio}

\begin{ejercicio}
    Para resolver el PVI
    \begin{equation*}
        \begin{cases}
            x' = f(t, x) \\
            x(t_0) = \mu
        \end{cases}
    \end{equation*}
    se propone el método:
    \begin{equation*}
        x_{n+1} = x_n + \frac{3}{2} h f(t_{n+1}, x_{n+1}) - \frac{1}{2} h f(t_n, x_n)
    \end{equation*}
    Estudia su A-estabilidad.\\


    Consideramos el PVI $x' = \lm x$, $x(0) = \mu$, con $\Re(\lm) < 0$. En este caso, el método es:
    \begin{align*}
        x_{n+1} &= x_n + \frac{3}{2} h \lm x_{n+1} - \frac{1}{2} h \lm x_n
        = \left(1 - \frac{1}{2} h \lm\right)x_n + \frac{3}{2} h \lm x_{n+1} \\
        &= \dfrac{1 - \frac{1}{2} h \lm}{1 - \frac{3}{2} h \lm} x_n
        = \left(\dfrac{2 - h \lm}{2 - 3h \lm}\right)x_n
        = \left(\dfrac{2 - \lm h}{2 - 3\lm h}\right)^n x_0
    \end{align*}

    Sea ahora $w = \lm h \in \bb{C}$, y calculemos la región de A-estabilidad del método:
    \begin{align*}
        \left|\dfrac{2 - w}{2 - 3w}\right| &< 1 \iff |2 - w| < |2 - 3w| \\
        \iff |2 - w|^2 &< |2 - 3w|^2
        \iff 4 + |w|^2 - 4\Re(w) < 4 + 9|w|^2 - 12\Re(w) \\
        \iff 8|w|^2 - 8\Re(w) &> 0 \iff |w|^2 - \Re(w) > 0
        \iff |w|^2 > \Re(w)
    \end{align*}

    Como la región de A-estabilidad contiene al semiplano izquierdo, el método es A-estable.
\end{ejercicio}

\begin{ejercicio}[DGIIM 2023/24]
    Para resolver numéricamente el PVI
    \begin{equation*}
        \begin{cases}
            x' = f(t, x) \\
            x(t_0) = \mu
        \end{cases}
    \end{equation*}
    se propone el método de Runge-Kutta Radau dado por el arreglo de Butcher
    \begin{equation*}
        \begin{array}{c|ccc}
            0 & \nicefrac{1}{4} & \nicefrac{-1}{4} \\
            \nicefrac{2}{3} & \nicefrac{1}{4} & \nicefrac{5}{12} \\ \hline
            & \nicefrac{1}{4} & \nicefrac{3}{4} 
        \end{array}
    \end{equation*}
    Estudia la convergencia del método. No es necesario que compruebes que $\Phi$ es Lipschitziana.\\

    Este método es dado por:
    \begin{align*}
        x_{n+1} &= x_n + h\left(\frac{1}{4}K_1 + \frac{3}{4}K_2\right) \\
        K_1 &= f(t_n, x_n + h\left(\frac{1}{4}K_1 - \frac{1}{4}K_2\right)) \\
        K_2 &= f\left(t_n + \frac{2}{3}h, x_n + h\left(\frac{1}{4}K_1 + \frac{5}{12}K_2\right)\right)
    \end{align*}

    Para estudiar la consistencia del método, estudiamos en primer lugar su estabilidad. Su polinomio característico es:
    \begin{align*}
        p(\lm) &= \lm -1 = 0 \iff \lm = 1
    \end{align*}

    Como la única raíz del polinomio es 1, el método es estable. Ahora hemos de estudiar la consistencia del método. Por la caracterización vista, tenemos que:
    \begin{itemize}
        \item $p(1)=0$, que se tiene.
        \item $\Phi(x(t_n), t_n, 0) = p'(1)f(t_n, x(t_n))$.
        
        Para comprobar esto, hemos de tener en cuenta que si $h=0$, entonces:
        \begin{align*}
            K_1 = K_2 = f(t_n, x_n)
        \end{align*}

        Por tanto:
        \begin{align*}
            \Phi(x(t_n), t_n, 0) &= \frac{1}{4}K_1 + \frac{3}{4}K_2 = \frac{1}{4}f(t_n, x_n) + \frac{3}{4}f(t_n, x_n) = f(t_n, x_n) = p'(1)f(t_n, x(t_n))
        \end{align*}

        Por tanto, se cumple la condición de consistencia. Notemos que simplemente es necesario que $\nicefrac{1}{4} + \frac{3}{4} = 1$, que es el caso.
    \end{itemize}

    Por tanto, el método es estable y consistente, por lo que es convergente.
\end{ejercicio}


\begin{ejercicio}[DGIIM 2023/24]
    Para aproximar la solución del PVI
    \begin{equation*}
        \begin{cases}
            x' = f(t, x) \\
            x(t_0) = \mu
        \end{cases}
    \end{equation*}
    se considera el método multipaso
    \begin{equation*}
        x_{n+3} = x_n + h(\beta_2 f_{n+2} + \beta_1 f_{n+1})
    \end{equation*}
    \begin{enumerate}
        \item ¿Qué relaciones deben existir entre los parámetros $\beta_1$ y $\beta_2$ para que el método anterior sea convergente? Justifica tu respuesta.
        
        En el ejercicio~\ref{ej:3.2.7} apartado~\ref{ej:3.2.7.1} vimos que este método es convergente si y solo si:
        \begin{equation*}
            \beta_1 + \beta_2 = 3
        \end{equation*}
        \item Calcula los coeficientes $\beta_1$ y $\beta_2$ para que el orden de convergencia sea máximo. Indica el orden de convergencia y el término principal del error de curvatura local.
        
        En el ejercicio~\ref{ej:3.2.7} apartado~\ref{ej:3.2.7.1} vimos que el método resultante es:
        \begin{equation*}
            x_{n+3} = x_n + \frac{h}{2}\left(7 f_{n+1} - f_{n+2}\right)
        \end{equation*}

        Además vimos que el orden del método era 2 y el término principal del error de truncatura local era:
        \begin{equation*}
            \frac{15}{4}h^3x^{(3)}(t_n)
        \end{equation*}
        \item Se pretende aproximar $x(1)$ donde $x(t)$ es la solución del PVI
            \begin{equation*}
                \begin{cases}
                    x' = x + t \\
                    x(0) = 1
                \end{cases}
            \end{equation*}
            Para ello, tomando $h = \nicefrac{1}{4}$, utiliza el método de Euler para obtener las condiciones iniciales que necesites. A continuación utiliza el método anterior hasta aproximar $x(1)$.\\

            El método de Euler es:
            \begin{align*}
                x_{n+1} &= x_n + hf(t_n, x_n) = x_n + h(x_n + t_n)
            \end{align*}

            El método propuesto es:
            \begin{align*}
                x_{n+3} &= x_n + \frac{h}{2}\left(7 f_{n+1} - f_{n+2}\right) = x_n + \frac{h}{2}\left(7(x_{n+1} + t_{n+1}) - (x_{n+2} + t_{n+2})\right)
            \end{align*}

            Las aproximaciones realizadas son:
            \begin{equation*}
                \begin{array}{c|c|c}
                    n & t_n & x_n\\ \hline
                    0 & 0 & 1 \\
                    1 & \nicefrac{1}{4} & 1.25 \\
                    2 & \nicefrac{1}{2} & 1.625 \\
                    3 & \nicefrac{3}{4} & 2.046875 \\
                    4 & 1 & 2.75976563
                \end{array}
            \end{equation*}
    \end{enumerate}
\end{ejercicio}
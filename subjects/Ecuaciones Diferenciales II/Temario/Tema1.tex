\chapter{Movimiento de partículas en un fluido}
\noindent
Fijado un espacio $\Omega\subseteq \mathbb{R}^3$, supondremos siempre que será abierto\footnote{Queremos estudiar movimientos de partículas en un fluido y pasan cosas no deseadas en la frontera.} y conexo\footnote{Por comodidad.}.

\begin{notacion}
    A cada punto de $\Omega$ lo notaremos normalmente por $p\in \Omega$, que tendrá coordenadas:
    \begin{equation*}
        p = (x,y,z)
    \end{equation*}
\end{notacion}

\noindent
El fluido suele llevar en cada punto una dirección y una velocidad, por lo que en cada punto $p\in \Omega$ tendremos un vector $v$ que determina la velocidad del fluido, la cual supondremos conocida siempre. Este vector no tiene por qué ser constante sino que puede depender del tiempo, por lo que generalmente $v$ será una función $v = v(t,p)$, es decir, $v:\mathbb{R}\times \Omega\to \mathbb{R}^3$ es una aplicación que a cada momento $t$ y posición $p$ le asigna un vector $v(t,p)$.\\

\noindent
Si tenemos una partícula en el fluido que se mueve esta determinará una trayectoria, que podemos modelar como una curva parametrizada $p(t)$.\\

\noindent
Podremos medir la velocidad de la partícula de dos formas: observando la velocidad de la partícula de forma interna (como el cuentakilómetros de un coche) o suponiendo que es una partícula que se deja llevar por la corriente y que su velocidad es la del fluido. La velocidad es la derivada de $p$.\\

\noindent
En el segundo caso:
\begin{equation*}
    \dot{p}(t) = V(t,p(t))
\end{equation*}
Estamos ante una ecuación diferencial. Observemos que es un sistema de primer orden en forma normal, puesto que las coordenadas de $p$ son funciones del tiempo. Si escribimos $V = (u,v,w)$ tenemos:
\begin{equation*}
    \left\{\begin{array}{l}
            \dot{x} = u(t,x,y,z) \\
            \dot{y} = v(t,x,y,z) \\
            \dot{z} = w(t,x,y,z)
    \end{array}\right.
\end{equation*}
Un sistema de 3 ecuaciones y 3 incógnitas, que conocidas las velocidades del fluido determina la trayectoria de la partícula. 

\begin{observacion}
    Observemos que en la notación primera hemos escrito explícitamente que $\dot{p}$ está en función de $t$. En la segunda notación estamos usando la notación habitual en las ecuaciones diferenciales, omitiendo la dependencia de $t$ y pensándola de forma implícita. Podemos así reescribir la primera ecuación como:
    \begin{equation*}
        \dot{p} = V(t,p)
    \end{equation*}
    Una vez denotamos $\dot{p}(t)$ estamos diciendo que es una solución concreta, por lo que será una variable dependiente de $t$. Sin embargo, cuando hablamos de $V(t,p)$ vemos $p$ como una variable independiente.
\end{observacion}

\noindent
Aparecerán sistemas autónomos, que representan fluidos estacionarios, donde la velocidad $V(t,p)$ no depende del tiempo.\\

\begin{ejemplo} % // TODO: Ver folio 1
    Comenzamos primero con dos ejemplos de fluidos estacionarios (el vector en cada posición no depende del tiempo):
    \begin{itemize}
        \item Consideramos $\Omega = \mathbb{R}^3$ y tomamos:
            \begin{equation*}
                V(t,x,y,z) = (0,1,0)
            \end{equation*}
            Observamos que es un sistema autónomo (no depende del tiempo) y en el que la velocidad tampoco depende de la posición:
            \begin{equation*}
                \left\{\begin{array}{l}
                        \dot{x} = 0 \\
                        \dot{y} = 1 \\
                        \dot{z} = 0 
                \end{array}\right.
            \end{equation*}
            Con lo que las soluciones son de la forma:
            \begin{align*}
                &x(t) = c_1 \\
                &y(t) = t + c_2 \\
                &z(t) = c_3
            \end{align*}
            Es una familia que depende de 3 parámetros.
        \item Tomamos la ecuación de un vórtice lineal, $\Omega = \mathbb{R}^3$ y:
            \begin{equation*}
                V(t,x,y,z) = (y, -x, 0)
            \end{equation*}
            Tenemos el sistema:
            \begin{equation*}
                \left\{\begin{array}{l}
                        \dot{x} = y \\
                        \dot{y} = -x \\
                        \dot{z} = 0
                \end{array}\right.
            \end{equation*}
            Es un sistema lineal homogéneo, que nos da las soluciones:
            \begin{align*}
                z(t) = c_3
            \end{align*}
            Reducimos a una ecuación de segundo orden, derivando en la primera:
            \begin{equation*}
                \ddot{x} + \dot{x} = 0
            \end{equation*}
            Por lo que:
            \begin{equation*}
                x(t) = c_1\cos(t) + c_2\sen(t)
            \end{equation*}
            Y también tendremos:
            \begin{equation*}
                y(t) = -c_1\sen(t) + c_2\cos(t)
            \end{equation*}
            Para ciertas condiciones iniciales $c_1,c_2,c_3\in \mathbb{R}$.
            % // TODO: Pensar por qué esto describe circunferencias
    \end{itemize}
\end{ejemplo}~\\

\noindent
Nuestro objetivo ahora es tratar de probar que el sistema:
\begin{equation*}
    \dot{p} = V(t,p)
\end{equation*}
con la condición inicial $p(t_0) = p_0$ tiene una solución. Luego trataremos de ver que en cada condición inicial tenemos una única solución. Demostraremos el Teorema de existencia y unicidad en cualquier número de dimensiones.

\begin{notacion}
    Notaremos a los puntos por $x=(x_1,\ldots,x_d)\in \mathbb{R}^d$ y al campo que define la ecuación diferencial por $X$, que será función de $t$ y de $x$, que estará definido en un conjunto $D\subseteq \mathbb{R}\times \mathbb{R}^d$ y exigiremos que sea abierto y conexo. Así, tendremos
    \Func{X}{D}{\bb{R}^d}{(t,x)}{X(t,x)}
    donde el campo $X$ tiene $d$ coordenadas:
    \begin{equation*}
        X = (X_1, \ldots, X_d)
    \end{equation*}
    donde tratamos de resolver la ecuación $\dot{x} = X(t,x)$, que en realidad es un sistema de ecuaciones:
    \begin{equation*}
        \left\{\begin{array}{l}
                \dot{x_1} = X_1(t,x_1,\ldots,x_d) \\
                \vdots \\
                \dot{x_d} = X_d(t,x_1,\ldots,x_d) 
        \end{array}\right.
    \end{equation*}
    Supondremos siempre que $X$ es una función continua.\\

    \noindent
    Tomaremos $(t_0,x_0) \in D$ y queremos resolver el problema de condiciones iniciales
    \begin{equation*}
        \dot{x} = X(t,x), \qquad x(t_0) = x_0
    \end{equation*}
    que consiste en resolver la ecuación diferencial superior mediante una solución que cumpla la condición enunciada.
\end{notacion}~\\

\section{Problema a resolver}
\noindent
Así, queremos resolver el problema:
\begin{equation}\label{eq:problema}
    \dot{x} = X(t,x)
\end{equation}
con $X:D\to \mathbb{R}^d$ continuo, donde $D\subset \mathbb{R}\times\mathbb{R}^d$ es un subconjunto abierto y conexo. La condición de que $X$ sea continuo es equivalente a que cada una de sus coordenadas
\begin{equation*}
    X = (X_1,\ldots,X_d)
\end{equation*}
sea una aplicación continua.

\begin{definicion}
    Una \textbf{solución} del problema~\eqref{eq:problema} es una aplicación $x:I\to \mathbb{R}^d$ donde  $I\subset \mathbb{R}$ es un intervalo\footnote{No necesariamente abierto.} de forma que $x(t)\subset D$:
    \begin{enumerate}
        \item[$i)$] $x(t)$ es derivable.
        \item[$ii)$] $(t,x(t))\in D\qquad \forall t\in I$.
        \item[$iii)$] $\dot{x}(t) = X(t,x(t)) \qquad \forall t\in I$.
    \end{enumerate}
\end{definicion}

\begin{observacion}
    Observemos que la definición de solución del problema planteado anteriormente es equivalente si sustituimos la condición de que $x$ sea derivable por la condición de que $x$ sea de clase 1, puesto que la condición $iii)$ nos da automáticamente la continuidad de la derivada de $x$. 

    \noindent
    Así, la condición $i)$ se puede sustituir por la condición $i')~x\in C^1(I,\mathbb{R}^d)$.
\end{observacion}

\begin{ejemplo}
    Veamos un par de ejemplos para fijar las ideas:
    \begin{enumerate}
        \item Consideramos $\dot{x} = x^2$ y la aplicación $x(t) = \dfrac{1}{1-t}$. Vamos a analizar el marco del problema.

            Tenemos en este caso $d=1$ y $D=\mathbb{R}^2$, puesto que tenemos el campo vectorial $X(t,x) = x^2$, que es continuo en todo $D=\mathbb{R}\times \mathbb{R}$. 

            Tenemos una primera solución en $I_1 = \left]-\infty,1\right[$, $x_1(t) = \frac{1}{1-t}$.

            Y otra solución en $I_2 = \left]1,+\infty\right[$, $x_2(t) = \frac{1}{1-t}$.

            Son \underline{dos soluciones distintas}, con la misma fórmula.
        \item Consideramos ahora $\dot{x} = \frac{x}{t}$ y la aplicación $x(t) = -7t$.

            Tenemos $d=1$ y el campo es $X(t,x) = \frac{x}{t}$, que tiene dos posibles dominios de definición:
            \begin{equation*}
                D_1 = \mathbb{R}^-\times \mathbb{R}, \qquad D_2 = \mathbb{R}^+\times \mathbb{R}
            \end{equation*}
            Tenemos en realidad dos ecuaciones diferenciales.

            Para discutir una de sus soluciones, si consideramos:
            \begin{equation*}
                I_1 = \mathbb{R}^-, \qquad I_2 = \mathbb{R}^+
            \end{equation*}
            tenemos que $x\big|_{I_1}$ es solución de la ecuación diferencial considerando el dominio $D_1$ y análogamente para $x\big|_{I_2}$ con el dominio $D_2$.
    \end{enumerate}
\end{ejemplo}

\noindent
Para una ecuación $\dot{x} = X(t,x)$ definida en un dominio $D\subset\mathbb{R}\times \mathbb{R}^d$ abierto y conexo, acompañaremos usualmente la ecuación de una \textbf{condición inicial}, que es fijar un punto $(t_0,x_0)\in D$ y obligaremos a la solución $x(t)$ de la ecuación que verifique la condición:
\begin{equation}\label{eq:condicion_inicial}
    x(t_0) = x_0
\end{equation}
Cuando nos refiramos próximamente al problema~\eqref{eq:problema} nos estaremos refiriendo usualmente a un problema de valores iniciales dado por la fórmula destacada y por la condición~\eqref{eq:condicion_inicial}.

\begin{ejemplo}
    En el primer ejemplo anterior tenemos para la condición inicial $x(0) = 1$ que la solución de $\dot{x} = x^2$ es $x:\left]-\infty,1\right[\to \mathbb{R}$ dada por:
    \begin{equation*}
        x(t) = \frac{1}{1-t}
    \end{equation*}
\end{ejemplo}

\begin{teo}[Cauchy-Peano, Existencia de soluciones de ecuaciones diferenciales.]\label{teo:existencia}
    Todo problema de valores iniciales admite una solución definida en algún intervalo\footnote{Por tanto, el Teorema nos da una solución local.} $I$ con $t_0\in \mathring{I}$.
\end{teo}

\begin{observacion}
    El ejepmlo anterior nos demuestra que el Teorema de Cauchy-Peano no puede generalizarse a otro que resuelva el problema de forma global, puesto que tenemos una solución para la ecuación que no puede extenderse a todo $\mathbb{R}$; a pesar de ser el dominio de la ecuación todo $\mathbb{R}^2$.
\end{observacion}

\noindent
Lo que venga a continuación estará destinado a probar el Teorema anterior.\\

\noindent
El primer paso será pasar el problema de valores iniciales a una ecuación integral, puesto que la ecuación diferencial y el problema de condiciones iniciales son muy intuitivos pero difíciles de manipular desde el punto de vista de las demostraciones.

\section{Ecuación integral de Volterra}
La ecuación integral de Volterra es:
\begin{equation}\label{eq:Volterra}
    x(t) = x_0 + \int_{t_0}^{t} X(s,x(s))~ds 
\end{equation}
Es la ecuación que obtenemos al integrar $\dot{x} = X(t,x)$. Así, a cada ecuación diferencial podemos asociarle una ecuación de Volterra y a cada ecuación de Volterra podemos asociarle una ecuación diferencial.

\begin{ejemplo}
    El problema de valores iniciales $\dot{x} = 3x$ con la condición inicial $x(2) = -5$ tiene ecuación integral de Volterra:
    \begin{equation}\label{eq:ejmVolterra}
        x(t) = -5 + \int_{2}^{t} 3x(s)~ds 
    \end{equation}
\end{ejemplo}

\begin{definicion}
    Una solución de~\eqref{eq:Volterra} es una función $x:I\to \mathbb{R}^d$ con $I$ un intervalo que contiene a $t_0$ en su interior y:
    \begin{enumerate}
        \item[$i)$] $x$ es continua.
        \item[$ii)$] $(t,x(t)) \in D\qquad \forall t\in I$.
        \item[$iii)$] Se cumple la condición~\eqref{eq:Volterra} para todo $t\in I$.
    \end{enumerate}
\end{definicion}

\begin{ejemplo}
    Una solución de la ecuación integral de Volterra~\eqref{eq:ejmVolterra} es:
    \begin{equation*}
        x(t) = -5e^{3(t-2)} \qquad \forall t\in \mathbb{R}
    \end{equation*}
\end{ejemplo}

\noindent
La estrategia será enunciar los Teoremas como ecuaciones diferenciales y realizar sus demostraciones con ecuaciones integrales.

\begin{prop}
    Los problemas~\eqref{eq:problema} y~\eqref{eq:Volterra} son equivalentes\footnote{Es decir, tienen las mismas soluciones.}.
    \begin{proof}
        Supondremos que tenemos una solución de una ecuación y tendremos que probar entonces que tenemos una solución de la otra ecuación. Basta aplicar el Teorema Fundamental del Cálculo en un caso y la Regla de Barrow en el otro.
        \begin{itemize}
            \item Supuesto que $x:I\to \mathbb{R}^d$ es solución de la ecuación~\eqref{eq:problema}, tenemos entonces que $x$ es una aplicación derivable que verifica\footnote{Observemos que la condición $ii)$ en el primer caso es equivalente a la condición $ii)$ del segundo caso.}:
                \begin{equation*}
                    \dot{x}(t) = X(t,x(t)) \qquad \forall t\in I
                \end{equation*}
                Por lo que $\dot{x}$ es una primitiva de la aplicación $t\mapsto X(t,x(t))$ definida en $I$, que sabemos que es continua. La Regla de Barrow nos dice entonces que fijado $t_0\in I$ se tiene:
                \begin{equation*}
                    \int_{t_0}^{t} X(s,x(s))~ds = x(t) - x(t_0) = x(t) - x_0 \qquad \forall t\in I
                \end{equation*}
                Y despejando obtenemos~\eqref{eq:Volterra}.
            \item Supuesto que $x:I\to \mathbb{R}^d$ es solución de la ecuación~\eqref{eq:Volterra}, tenemos en este caso que $x$ es una aplicación continua que verifica:
                \begin{equation*}
                    x(t) = x_0 + \int_{t_0}^{t} X(s,x(s))~ds  \qquad \forall t\in I
                \end{equation*}
                Como $x$ es continua, la aplicación $s\mapsto X(s,x(s))$ y de dominio $I$ será también continua. Bajo estas hipótesis, el Teorema Fundamental del Cálculo nos dice que la aplicación
                \begin{equation*}
                    t\longmapsto \int_{t_0}^{t} X(s,x(s))~ds 
                \end{equation*}
                de dominio $I$ es derivable, por lo que también lo será la aplicación $x$, y su derivada es:
                \begin{equation*}
                    \dot{x}(t) = X(t,x(t)) \qquad \forall t\in I
                \end{equation*}
                Hemos obtenido que $x$ es solución de~\eqref{eq:problema}, y es claro que $x(t_0) = x_0$.
        \end{itemize}
    \end{proof}
\end{prop}

\subsection{El Teorema global}
\noindent
La estrategia a seguir será probar un Teorema global con hipótesis extra para luego retringir el problema y obtener la demostración del Teorema local.

\begin{teo}[global de existencia]\label{teo:global_existencia}
    Sea $D=\left]a,b\right[\times \mathbb{R}^d$ para ciertos $a,b\in \mathbb{R}$ y $X:\left]a,b\right[\times \mathbb{R}^d\to \mathbb{R}^d$ continuo de forma que
    \begin{equation*}
        \exists M>0 : \|X(t,x)\|\leq M \qquad \forall (t,x)\in D
    \end{equation*}
    Entonces~\eqref{eq:problema} tiene una solución definida en todo el intervalo $\left]a,b\right[$.
\end{teo}

\begin{ejemplo}
    Familiaricémonos con este problema.
    \begin{enumerate}
        \item Consideramos el sistema
            \begin{equation*}
                \left\{\begin{array}{ll}
                     \dot{x}_1 = \dfrac{x_2}{1+x_2^2 + x_1^2} + t\sen(x_1),& \qquad x_1(0) = 3 \\
                                                                           &\\
                     \dot{x}_2 = e^{-x_1^2} + \sqrt{1-t^2},& \qquad x_2(0) = 7 \\
                \end{array}\right. 
            \end{equation*}
            Aquí tenemos $d=2$, $\left]a,b\right[ = \left]-1,1\right[$, con $X:\left]-1,1\right[\times \mathbb{R}^2\to \mathbb{R}^2$ continuo.

            Veamos que $X$ está acotado, como todas las normas son equivalentes, tomaremos la norma del máximo: $\|(x_1,x_2)\| = \max\{|x_1|,|x_2|\}$:
            \begin{align*}
                \|X(t,x)\| &\leq\max\left\{2,2\right\} = 2 \qquad \forall (t,x)\in \left]-1,1\right[\times \mathbb{R}^2
            \end{align*}
            Tenemos además que $t_0 = 0\in \left]a,b\right[$ así como que $x_0 = (3,7) \in \mathbb{R}^2$.
        \item Veamos ahora que la hipótesis de que $X$ es acotado es esencial, puesto que el problema de valores iniciales $\dot{x} = x^2$, $x(0) = 1$ con solución
            \begin{equation*}
                x(t) = \frac{1}{1-t}, \qquad t\in \left]-3,1\right[
            \end{equation*}
            donde tenemos\footnote{Podríamos haber tomado $D=\mathbb{R}\times \mathbb{R}$, pero queremos verificar las hipótesis del Teorema.} $D=\left]-3,3\right[\times \mathbb{R}$. Próximamente veremos que esta solución es la única para la condición inicial enunciada, lo que nos garantizará que esta solución no puede extenderse a otra que esté definida en $\left]-3,3\right[$.
    \end{enumerate}
\end{ejemplo}

\noindent
Vamos a ver a continuación que el Teorema~\ref{teo:existencia} puede deducirse a partir del Teorema~\ref{teo:global_existencia}, por lo que nuestro futuro trabajo será probar este segundo. Para probar esta relación usaremos el Lema del Pegado, que ya conocíamos de Topología I.

\begin{lema}\label{lema:del_pegado}
    Sean $X,Y$ espacios métricos y $F_1,F_2\subset X$ dos cerrados de forma que $F_1\cup F_2 = X$. Sean $f_i:F_i\to Y$ continuas para $i \in \{1,2\}$ verificando que $f_1 = f_2$ en $F_1\cap F_2$. Entonces la función $f:X\to Y$ dada por:
    \begin{equation*}
        f(x) = \left\{\begin{array}{ll}
            f_1(x) & \text{si\ } x\in F_1 \\
            f_2(x) & \text{si\ } x\in F_2
        \end{array}\right. 
    \end{equation*}
    está bien definida y es continua.
\end{lema}

\begin{prop}
    Del Teorema~\ref{teo:global_existencia} puede deducirse el Teorema~\ref{teo:existencia}.
    \begin{proof} 
        Como $D$ es abierto y $(t_0,x_0)\in D$, podemos tomar $a,b>0$ de forma que:
        \begin{equation*}
            R = \{(t,x)\in \mathbb{R}\times\mathbb{R}^d : |t-t_0|\leq a, \|x-x_0\|\leq b\} \subset D
        \end{equation*} % // TODO: Meter dibujo 1
        Tomaremos además $0<b^\ast<b$ y consideraremos:
        \begin{equation*}
            R^\ast = \{(t,x)\in \mathbb{R}\times\mathbb{R}^d : |t-t_0|\leq a, \|x-x_0\|\leq b^\ast\} \subset D
        \end{equation*} % // TODO: Meter dibujo 2
        Definimos $\psi:\left]t_0-a,t_0+a\right[\times \mathbb{R}^d\to \mathbb{R}$ continua de forma que:
        \begin{gather*}
            \psi = 1 \quad \text{en}\quad \|x-x_0\| < b^\ast \\
            \psi = 0 \quad \text{en}\quad \|x-x_0\| > b \\
            0\leq \psi \leq 1 \quad \text{siempre}
        \end{gather*}
        Y definimos el campo modificado $X^\ast:\left]t_0-a,t_0+a\right[\times \mathbb{R}^d\to \mathbb{R}^d$ dado por:
        \begin{equation*}
            X^\ast(t,x) = \left\{\begin{array}{ll}
                \psi(t,x)\cdot X(t,x) & \text{si\ }\|x-x_0\|\leq b  \\
                 0 & \text{si\ } \|x-x_0\| > b
            \end{array}\right. 
        \end{equation*}
        Vemos que $X(t,x) = X^\ast(t,x)$ para todo $(t,x)\in R^\ast$.\\

        \noindent
        Buscamos aplicar ahora el Teorema~\ref{teo:global_existencia} a $\dot{x} = X^\ast(t,x)$, $x(t_0) = x_0$. Falta comprobar la contiuidad de $X^\ast$ y su acotación.

        \begin{itemize}
            \item Para la contuidad de $X^\ast$, si consideramos en el espacio $\left]t_0-a,t_0+a\right[\times \mathbb{R}^d$:
                \begin{align*}
                    F_1 &= \{(t,x)\in \mathbb{R}\times \mathbb{R}^d : |t-t_0|<a, \|x-x_0\| \leq b\} \\
                    F_2 &= \{(t,x)\in \mathbb{R}\times \mathbb{R}^d : |t-t_0|<a, \|x-x_0\| \geq b\} 
                \end{align*}
                Vemos que definiendo $f_1 = \psi \cdot X$, $f_2 = 0$ se tiene que\footnote{Por la contiuidad de $\psi$ tenemos que $\psi(x) = 0$ cuando $\|x-x_0\| = b$.} $f_1 = f_2$ en $F_1\cap F_2$. Aplicando el Lema~\ref{lema:del_pegado} obtenemos que la función $X^\ast$ es continua.
            \item $X$ es continuo y $R\subset D$ es compacto, por lo que:
                \begin{equation*}
                    \exists M>0 : \|X(t,x)\|\leq M \qquad \forall (t,x)\in R
                \end{equation*}
                Como $\psi \leq 1$ obtenemos que $X^\ast$ es también acotada a partir de su definición.
        \end{itemize}
        Aplicando ahora el Teorema~\ref{teo:global_existencia} obtenemos que existe $x:\left]t_0-a,t_0+a\right[\to \mathbb{R}^d$ que es solución del problema:
        \begin{equation*}
            \dot{x}(t) = X^\ast(t,x(t)), \qquad x(t_0) = x_0
        \end{equation*} % // TODO: COpiar dibujo 3
        Vemos que $x(t)$ no puede (quizás) ser solución del problema planteado con el campo $X$ en el dominio $D$, pero sí que nos podemos restringir a un entorno. Tenemos que:
        \begin{gather*}
            \dot{x}(t) = X(t,x) = X^\ast(t,x) \quad \text{si}\quad \|x-x_0\| < b^\ast \\
            x(t_0) = x_0, \quad \qquad x(t)\quad \text{continua}
        \end{gather*}
        Y además:
        \begin{equation*}
            \exists \delta>0 : \|x(t)-x_0\| < b^\ast \qquad \forall t\in [t_0-\delta,t_0+\delta]
        \end{equation*}
        Con lo que $x\big|_{[t_0-\delta,t_0+\delta]}$ sí que es solución de $\dot{x} = X(t,x)$, $x(t_0) = x_0$.
    \end{proof}
\end{prop}

\subsection{Demostración del Teorema global}
\noindent
Nuestro interés será ahora probar el Teorema~\ref{teo:global_existencia}. Recordando las hipótesis, tenemos una función $X:\left]a,b\right[\times \mathbb{R}^d\to \mathbb{R}^d$ continuo y acotado:
\begin{equation*}
    \exists M:\|X(t,x)\|\leq M \qquad \forall (t,x)\in \left]a,b\right[\times \mathbb{R}^d
\end{equation*}
La demostración se dividirá en 3 etapas:

\begin{description}
    \item [1 - Construcción de soluciones aproximadas.] Fijado $\varepsilon>0$, definiremos \newline $x_{\varepsilon}:\left]a,b\right[\to \mathbb{R}^d$ continua de forma que se verifica\footnote{La constante $M\varepsilon$ es por comodidad, se podría haber sustituido por $\varepsilon$.}:
        \begin{equation*}
            \left\|x_{\varepsilon} -x_0- \int_{t_0}^{t} X(s,x(s))~ds \right\| \leq M \varepsilon \qquad \forall t\in \left]a,b\right[
        \end{equation*}
        Estas funciones $x_{\varepsilon}$ serán soluciones aproximasdas a la ecuación de Volterra que estamos buscando, y seguiremos el método de Tonelli para construirlas.
    \item [2 - Argumento de compacidad (Ascoli-Arzelá).] En esta etapa queremos pasar al límite de una sucesión de aproximaciones $x_{\varepsilon_n}$, que queremos que tengan límite, para lo que nos serán de especial relevancia los conjuntos compactos en un espacio de funciones. La convergencia que nos interesará será la convergencia uniforme.
    \item [3 - Paso al límite.] Teniendo $n$ a infinito obtendremos la solución como límite de la sucesión construida.
\end{description}

% // TODO: Meter idea de Tonelli

\begin{ejemplo}
    Consideramos $x'=\sen x$, $x(0) = \frac{\pi}{2}$, $[0,2]$ y $\varepsilon=1$. La solución aproximada sería:
    \begin{equation*}
        x_1(t) = \left\{\begin{array}{ll}
                \dfrac{\pi}{2} & \text{si\ } t\in [0,1] \\
                              & \\
                \displaystyle \frac{\pi}{2}+\int_{0}^{t-1} \sen x_1(s)~ds = \frac{\pi}{2}+\int_{0}^{t-1}ds = \frac{\pi}{2}+t-1 & \text{si\ } t\in [1,2]
        \end{array}\right. 
    \end{equation*}
\end{ejemplo}
